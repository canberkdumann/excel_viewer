# perfo_destek_app.py
# Streamlit arayÃ¼zÃ¼: "Perfo Destek Ã‡Ã¶zÃ¼mleri.xlsx" gibi dosyalar iÃ§in
# Kolonlar: Talep No, Talep AÃ§Ä±klamasÄ±, YanÄ±t, YanÄ±t AÃ§Ä±klamasÄ± (ve diÄŸerleri)
# Ã‡alÄ±ÅŸtÄ±rma: streamlit run perfo_destek_app.py


import streamlit as st
import pandas as pd
import numpy as np
import re
import sys
import io
import math
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import time
import hashlib
import pickle
from datetime import datetime, timedelta
from contextlib import contextmanager
try:
    import speech_recognition as sr
    SPEECH_AVAILABLE = True
except ImportError:
    SPEECH_AVAILABLE = False
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Any, Optional


st.set_page_config(
    page_title="ğŸš€ Enterprise Excel GÃ¶rÃ¼ntÃ¼leyici",
    page_icon="ÄŸÅ¸â€”â€šÃ¯Â¸Â",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ÄŸÅ¸Å¡â‚¬ MODERN ENTERPRISE FEATURES
# ===============================

# 1. PERFORMANCE MONITORING SYSTEM
class PerformanceMonitor:
    def __init__(self):
        self.operations = []
        self.operation_history = []
    
    def start_operation(self, operation_name):
        operation = {
            'operation': operation_name,
            'start_time': datetime.now(),
            'timestamp': datetime.now()
        }
        return operation
    
    def end_operation(self, operation, success=True):
        end_time = datetime.now()
        operation['end_time'] = end_time
        operation['duration'] = (end_time - operation['start_time']).total_seconds()
        operation['success'] = success
        
        self.operations.append(operation)
        self.operation_history.append(operation)
        
        # Keep only last 100 operations for memory efficiency
        if len(self.operation_history) > 100:
            self.operation_history = self.operation_history[-100:]
        
        return operation
    
    @contextmanager
    def track_operation(self, operation_name):
        operation = self.start_operation(operation_name)
        try:
            yield operation
            self.end_operation(operation, True)
        except Exception as e:
            self.end_operation(operation, False)
            raise
    
    def get_stats(self):
        """Get performance statistics"""
        if not self.operations:
            return None
        
        total_operations = len(self.operations)
        successful_operations = sum(1 for op in self.operations if op.get('success', False))
        failed_operations = total_operations - successful_operations
        
        durations = [op['duration'] for op in self.operations if 'duration' in op]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        return {
            'total_operations': total_operations,
            'successful_operations': successful_operations,
            'failed_operations': failed_operations,
            'average_execution_time': avg_duration,
            'success_rate': (successful_operations / total_operations * 100) if total_operations > 0 else 0
        }

# 2. SMART CACHE SYSTEM
class SmartCache:
    def __init__(self, max_size=100):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
    
    def _generate_key(self, data):
        """Generate unique key for data"""
        if isinstance(data, str):
            return hashlib.md5(data.encode()).hexdigest()
        return hashlib.md5(str(data).encode()).hexdigest()
    
    def get(self, key):
        if key in self.cache:
            self.access_times[key] = time.time()
            self._track_hit()
            return self.cache[key]
        else:
            self._track_miss()
            return None
    
    def set(self, key, value):
        if len(self.cache) >= self.max_size:
            # Remove oldest accessed item
            oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
            del self.cache[oldest_key]
            del self.access_times[oldest_key]
        
        self.cache[key] = value
        self.access_times[key] = time.time()
    
    def clear(self):
        self.cache.clear()
        self.access_times.clear()
    
    def get_stats(self):
        """Get cache statistics"""
        # Initialize counters if not exist
        if not hasattr(self, 'hits'):
            self.hits = 0
        if not hasattr(self, 'misses'):
            self.misses = 0
        if not hasattr(self, 'total_requests'):
            self.total_requests = 0
        
        return {
            'hits': getattr(self, 'hits', 0),
            'misses': getattr(self, 'misses', 0),
            'total_requests': getattr(self, 'total_requests', 0),
            'cache_size': len(self.cache),
            'max_size': self.max_size,
            'hit_rate': (getattr(self, 'hits', 0) / max(getattr(self, 'total_requests', 1), 1)) * 100
        }
    
    def _track_hit(self):
        """Track cache hit"""
        if not hasattr(self, 'hits'):
            self.hits = 0
        if not hasattr(self, 'total_requests'):
            self.total_requests = 0
        self.hits += 1
        self.total_requests += 1
    
    def _track_miss(self):
        """Track cache miss"""
        if not hasattr(self, 'misses'):
            self.misses = 0
        if not hasattr(self, 'total_requests'):
            self.total_requests = 0
        self.misses += 1
        self.total_requests += 1

# 3. ADVANCED ERROR HANDLER
class SmartErrorHandler:
    @staticmethod
    def categorize_error(error):
        error_str = str(error).lower()
        
        if 'memory' in error_str or 'ram' in error_str:
            return {
                'category': 'Memory',
                'severity': 'High',
                'message': 'Bellek yetersizliÃ„Å¸i tespit edildi',
                'solution': 'Dosya boyutunu kÃƒÂ¼ÃƒÂ§ÃƒÂ¼ltÃƒÂ¼n veya sayfalama kullanÃ„Â±n',
                'icon': 'ÄŸÅ¸Â§Â '
            }
        elif 'file' in error_str or 'no such file' in error_str:
            return {
                'category': 'File',
                'severity': 'Medium',
                'message': 'Dosya bulunamadÃ„Â± veya okunamadÃ„Â±',
                'solution': 'Dosya yolunu kontrol edin ve dosyanÃ„Â±n mevcut olduÃ„Å¸undan emin olun',
                'icon': 'ÄŸÅ¸â€œÂ'
            }
        elif 'permission' in error_str or 'access' in error_str:
            return {
                'category': 'Permission',
                'severity': 'Medium',
                'message': 'Dosya eriÃ…Å¸im izni hatasÃ„Â±',
                'solution': 'DosyanÃ„Â±n aÃƒÂ§Ã„Â±k olmadÃ„Â±Ã„Å¸Ã„Â±ndan emin olun veya yÃƒÂ¶netici izinleri alÃ„Â±n',
                'icon': 'ÄŸÅ¸â€â€™'
            }
        elif 'encoding' in error_str or 'decode' in error_str:
            return {
                'category': 'Encoding',
                'severity': 'Low',
                'message': 'Karakter kodlama hatasÃ„Â±',
                'solution': 'DosyayÃ„Â± UTF-8 formatÃ„Â±nda kaydedin',
                'icon': 'ÄŸÅ¸â€Â¤'
            }
        else:
            return {
                'category': 'General',
                'severity': 'Medium',
                'message': 'Beklenmeyen hata',
                'solution': 'DosyayÃ„Â± kontrol edin ve tekrar deneyin',
                'icon': 'Ã¢Å¡Â Ã¯Â¸Â'
            }
    
    @staticmethod
    def display_error(error, context=""):
        error_info = SmartErrorHandler.categorize_error(error)
        
        with st.container():
            st.error(f"""
            {error_info['icon']} **{error_info['category']} HatasÃ„Â±** ({error_info['severity']} Ãƒâ€“ncelik)
            
            **Problem:** {error_info['message']}
            
            **Ãƒâ€¡ÃƒÂ¶zÃƒÂ¼m:** {error_info['solution']}
            
            {f"**BaÃ„Å¸lam:** {context}" if context else ""}
            """)

# 4. DATA VALIDATOR
class DataValidator:
    @staticmethod
    def validate_excel_file(df: pd.DataFrame) -> Dict[str, Any]:
        """Comprehensive data quality analysis"""
        total_cells = df.shape[0] * df.shape[1]
        null_cells = df.isnull().sum().sum()
        duplicate_rows = df.duplicated().sum()
        
        # Calculate quality score
        null_ratio = null_cells / total_cells if total_cells > 0 else 0
        duplicate_ratio = duplicate_rows / len(df) if len(df) > 0 else 0
        
        quality_score = max(0, 100 - (null_ratio * 50) - (duplicate_ratio * 30))
        
        issues = []
        recommendations = []
        
        # Check for issues
        if null_ratio > 0.1:
            issues.append(f"YÃƒÂ¼ksek boÃ…Å¸ veri oranÃ„Â±: %{null_ratio*100:.1f}")
            recommendations.append("BoÃ…Å¸ hÃƒÂ¼creleri doldurun veya ilgili satÃ„Â±rlarÃ„Â± kaldÃ„Â±rÃ„Â±n")
        
        if duplicate_rows > 0:
            issues.append(f"{duplicate_rows} duplicate satÃ„Â±r bulundu")
            recommendations.append("Duplicate satÃ„Â±rlarÃ„Â± kaldÃ„Â±rÃ„Â±n")
        
        if df.shape[1] > 20:
            recommendations.append("Ãƒâ€¡ok sayÃ„Â±da sÃƒÂ¼tun var - gereksiz olanlarÃ„Â± gizlemeyi dÃƒÂ¼Ã…Å¸ÃƒÂ¼nÃƒÂ¼n")
        
        if df.shape[0] > 10000:
            recommendations.append("BÃƒÂ¼yÃƒÂ¼k veri seti - filtreleme ve sayfalama kullanÃ„Â±n")
        
        return {
            'is_valid': quality_score > 60,
            'quality_score': quality_score,
            'issues': issues,
            'recommendations': recommendations,
            'stats': {
                'total_rows': df.shape[0],
                'total_columns': df.shape[1],
                'null_cells': null_cells,
                'duplicate_rows': duplicate_rows,
                'null_ratio': null_ratio,
                'duplicate_ratio': duplicate_ratio
            }
        }

# 5. SMART VISUALIZER
class SmartVisualizer:
    @staticmethod
    def create_data_overview_chart(df: pd.DataFrame):
        """Create data type distribution chart"""
        dtype_counts = df.dtypes.value_counts()
        
        fig = px.pie(
            values=dtype_counts.values,
            names=[str(dtype) for dtype in dtype_counts.index],
            title="ÄŸÅ¸â€œÅ  Veri TÃƒÂ¼rÃƒÂ¼ DaÃ„Å¸Ã„Â±lÃ„Â±mÃ„Â±"
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        return fig
    
    @staticmethod
    def create_quality_dashboard(df: pd.DataFrame):
        """Create data quality dashboard"""
        null_counts = df.isnull().sum()
        
        fig = px.bar(
            x=null_counts.index,
            y=null_counts.values,
            title="ÄŸÅ¸â€Â SÃƒÂ¼tun BazlÃ„Â± BoÃ…Å¸ Veri Analizi",
            labels={'x': 'SÃƒÂ¼tunlar', 'y': 'BoÃ…Å¸ HÃƒÂ¼cre SayÃ„Â±sÃ„Â±'}
        )
        
        fig.update_layout(xaxis_tickangle=-45)
        return fig
    
    @staticmethod
    def create_smart_chart(df: pd.DataFrame, column: str):
        """Create smart chart based on data type and distribution"""
        try:
            if column not in df.columns:
                return None
            
            data = df[column].dropna()
            if len(data) == 0:
                return None
            
            # Determine chart type based on data
            if pd.api.types.is_numeric_dtype(data):
                # For numeric data, create histogram with distribution info
                fig = px.histogram(
                    data, 
                    x=data,
                    title=f"ÄŸÅ¸â€œÅ  {column} - DaÃ„Å¸Ã„Â±lÃ„Â±m Analizi",
                    nbins=min(30, len(data.unique())),
                    marginal="box"  # Add box plot on top
                )
                
                # Add statistical annotations
                mean_val = data.mean()
                median_val = data.median()
                
                fig.add_vline(x=mean_val, line_dash="dash", line_color="red", 
                             annotation_text=f"Ortalama: {mean_val:.2f}")
                fig.add_vline(x=median_val, line_dash="dot", line_color="blue", 
                             annotation_text=f"Medyan: {median_val:.2f}")
                
                fig.update_layout(
                    showlegend=True,
                    xaxis_title=column,
                    yaxis_title="Frekans"
                )
                
            elif pd.api.types.is_categorical_dtype(data) or data.dtype == 'object':
                # For categorical data, create bar chart
                value_counts = data.value_counts().head(20)  # Top 20 values
                
                fig = px.bar(
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"ÄŸÅ¸â€œÅ  {column} - En SÃ„Â±k DeÃ„Å¸erler (Top 20)",
                    labels={'x': column, 'y': 'Frekans'}
                )
                
                fig.update_layout(xaxis_tickangle=-45)
                
            else:
                # For other data types, create simple value counts
                value_counts = data.value_counts().head(10)
                
                fig = px.pie(
                    values=value_counts.values,
                    names=value_counts.index,
                    title=f"ÄŸÅ¸â€œÅ  {column} - DeÃ„Å¸er DaÃ„Å¸Ã„Â±lÃ„Â±mÃ„Â±"
                )
            
            # Update layout for better appearance
            fig.update_layout(
                height=400,
                showlegend=True,
                font=dict(size=12)
            )
            
            return fig
            
        except Exception as e:
            # Return None if chart creation fails
            return None

# Initialize systems
if 'perf_monitor' not in st.session_state:
    st.session_state.perf_monitor = PerformanceMonitor()

if 'smart_cache' not in st.session_state:
    st.session_state.smart_cache = SmartCache()

# Favori sistemi iÃƒÂ§in session state
if 'favorites' not in st.session_state:
    st.session_state.favorites = []

error_handler = SmartErrorHandler()
data_validator = DataValidator()
smart_visualizer = SmartVisualizer()

# uploads klasÃƒÂ¶rÃƒÂ¼ndeki dosyalarÃ„Â± listele
import os
uploads_dir = "uploads"
uploads_path = os.path.join(os.getcwd(), uploads_dir)
if not os.path.exists(uploads_path):
    os.makedirs(uploads_path)

st.sidebar.header("YÃƒÂ¼klenen Excel DosyalarÃ„Â±")
excel_files = [f for f in os.listdir(uploads_path) if f.endswith(".xlsx")]

# Dosya seÃƒÂ§imi iÃƒÂ§in session state
if "selected_file_key" not in st.session_state:
    st.session_state["selected_file_key"] = None

selected_file = st.sidebar.selectbox(
    "Daha ÃƒÂ¶nce yÃƒÂ¼klenen dosyalar",
    options=["Dosya seÃƒÂ§in..."] + excel_files,
    key="file_selector"
) if excel_files else None

# SeÃƒÂ§ilen dosyayÃ„Â± kontrol et
if selected_file and selected_file != "Dosya seÃƒÂ§in...":
    st.session_state["selected_file_key"] = selected_file
else:
    selected_file = None

# Dosya silme ÃƒÂ¶zelliÃ„Å¸i
if excel_files:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ÄŸÅ¸â€”â€˜Ã¯Â¸Â Dosya YÃƒÂ¶netimi")
    
    # Her dosya iÃƒÂ§in silme butonu
    files_to_delete = []
    for file in excel_files:
        col1, col2 = st.sidebar.columns([3, 1])
        col1.text(file[:20] + "..." if len(file) > 20 else file)
        if col2.button("ÄŸÅ¸â€”â€˜Ã¯Â¸Â", key=f"delete_{file}", help=f"{file} dosyasÃ„Â±nÃ„Â± sil"):
            files_to_delete.append(file)
    
    # Silme iÃ…Å¸lemini gerÃƒÂ§ekleÃ…Å¸tir
    for file_to_delete in files_to_delete:
        try:
            file_path = os.path.join(uploads_path, file_to_delete)
            os.remove(file_path)
            st.sidebar.success(f"Ã¢Å“â€¦ {file_to_delete} silindi!")
            
            # EÃ„Å¸er silinen dosya seÃƒÂ§ili dosyaysa, session'Ã„Â± temizle
            if st.session_state.get("selected_file_key") == file_to_delete:
                st.session_state["selected_file_key"] = None
            
            # SayfayÃ„Â± yenile
            st.rerun()
        except Exception as e:
            st.sidebar.error(f"Ã¢ÂÅ’ Dosya silinemedi: {e}")
    
    # TÃƒÂ¼m dosyalarÃ„Â± silme butonu
    if len(excel_files) > 1:
        st.sidebar.markdown("---")
        if st.sidebar.button("ÄŸÅ¸â€”â€˜Ã¯Â¸Â TÃƒÂ¼m DosyalarÃ„Â± Sil", help="TÃƒÂ¼m Excel dosyalarÃ„Â±nÃ„Â± sil"):
            try:
                for file in excel_files:
                    file_path = os.path.join(uploads_path, file)
                    os.remove(file_path)
                
                # Session'Ã„Â± temizle
                st.session_state["selected_file_key"] = None
                st.sidebar.success(f"Ã¢Å“â€¦ {len(excel_files)} dosya silindi!")
                st.rerun()
            except Exception as e:
                st.sidebar.error(f"Ã¢ÂÅ’ Dosyalar silinemedi: {e}")

# -------------------------
# Sayfa ayarlarÃ„Â±
# -------------------------
st.set_page_config(
    page_title="Perfo Destek Ãƒâ€¡ÃƒÂ¶zÃƒÂ¼mleri - Talepler ArayÃƒÂ¼zÃƒÂ¼",
    page_icon="ÄŸÅ¸â€”â€šÃ¯Â¸Â",
    layout="wide",
    initial_sidebar_state="expanded",
)

# -------------------------
# YardÃ„Â±mcÃ„Â± fonksiyonlar
# -------------------------

def get_voice_input():
    """Sesli arama iÃƒÂ§in mikrofon giriÃ…Å¸i alÃ„Â±r"""
    if not SPEECH_AVAILABLE:
        return "Sesli arama kÃƒÂ¼tÃƒÂ¼phanesi yÃƒÂ¼klÃƒÂ¼ deÃ„Å¸il. 'pip install SpeechRecognition pyaudio' komutunu ÃƒÂ§alÃ„Â±Ã…Å¸tÃ„Â±rÃ„Â±n."
    
    try:
        r = sr.Recognizer()
        with sr.Microphone() as source:
            st.info("ÄŸÅ¸ÂÂ¤ KonuÃ…Å¸un... (3 saniye bekleniyor)")
            r.adjust_for_ambient_noise(source, duration=1)
            audio = r.listen(source, timeout=3)
        
        text = r.recognize_google(audio, language='tr-TR')
        return text
    except sr.WaitTimeoutError:
        return "Zaman aÃ…Å¸Ã„Â±mÃ„Â± - tekrar deneyin"
    except sr.UnknownValueError:
        return "Ses anlaÃ…Å¸Ã„Â±lamadÃ„Â±"
    except sr.RequestError:
        return "Ses tanÃ„Â±ma servisi hatasÃ„Â±"
    except Exception as e:
        return f"Hata: {str(e)}"

def generate_smart_summary(df):
    """Excel dosyasÃ„Â± iÃƒÂ§in basit ve kullanÃ„Â±Ã…Å¸lÃ„Â± ÃƒÂ¶zet oluÃ…Å¸turur"""
    
    # En sÃ„Â±k tekrar eden kelimeleri bul
    all_text = ""
    text_cols = df.select_dtypes(include=['object']).columns
    for col in text_cols:
        all_text += " " + df[col].astype(str).str.cat(sep=" ")
    
    # Kelimeleri ayÃ„Â±kla ve say
    words = re.findall(r'\b\w{3,}\b', all_text.lower())
    stop_words = {'iÃƒÂ§in', 'olan', 'olan', 'ile', 'bir', 'bu', 've', 'ama', 'fakat', 'nan', 'none'}
    words = [w for w in words if w not in stop_words and not w.isdigit()]
    
    from collections import Counter
    word_counts = Counter(words).most_common(5)
    
    # Basit analiz
    total_rows = len(df)
    total_cols = len(df.columns)
    empty_cells = df.isnull().sum().sum()
    
    # Excel dosyasÃ„Â±nÃ„Â± akÃ„Â±llÃ„Â± analiz et ve ÃƒÂ¶zetle
    excel_analysis = analyze_excel_content(df, word_counts, total_rows, total_cols)
    
    # AkÃ„Â±llÃ„Â± ÃƒÂ¶neriler
    suggestions = []
    if empty_cells > total_rows * 0.1:
        suggestions.append("ÄŸÅ¸â€œÂ Ãƒâ€¡ok sayÃ„Â±da boÃ…Å¸ hÃƒÂ¼cre var - veri temizliÃ„Å¸i yapÃ„Â±labilir")
    
    if total_rows > 1000:
        suggestions.append("ÄŸÅ¸â€œÅ  BÃƒÂ¼yÃƒÂ¼k veri seti - filtreleme kullanmanÃ„Â±z ÃƒÂ¶nerilir")
    
    if len(text_cols) > 5:
        suggestions.append("ÄŸÅ¸â€Â Ãƒâ€¡ok sayÃ„Â±da metin sÃƒÂ¼tunu - arama ÃƒÂ¶zelliÃ„Å¸ini kullanÃ„Â±n")
    
    return {
        "toplam_satir": total_rows,
        "toplam_sutun": total_cols,
        "bos_hucre": int(empty_cells),
        "en_sik_kelimeler": word_counts,
        "oneriler": suggestions,
        "akilli_analiz": excel_analysis
    }

def analyze_excel_content(df, top_words, rows, cols):
    """Excel iÃƒÂ§eriÃ„Å¸ini analiz edip kÃ„Â±sa ÃƒÂ¶zet cÃƒÂ¼mleler oluÃ…Å¸turur"""
    analysis = []
    
    # Dosya tÃƒÂ¼rÃƒÂ¼ analizi
    if any(keyword in ' '.join([word[0] for word in top_words]) for keyword in ['talep', 'ticket', 'request']):
        analysis.append("ÄŸÅ¸ÂÂ« Bu bir talep/destek dosyasÃ„Â± gibi gÃƒÂ¶rÃƒÂ¼nÃƒÂ¼yor.")
    elif any(keyword in ' '.join([word[0] for word in top_words]) for keyword in ['mÃƒÂ¼Ã…Å¸teri', 'customer', 'client']):
        analysis.append("ÄŸÅ¸â€˜Â¤ MÃƒÂ¼Ã…Å¸teri bilgileri iÃƒÂ§eren bir dosya.")
    elif any(keyword in ' '.join([word[0] for word in top_words]) for keyword in ['satÃ„Â±Ã…Å¸', 'sales', 'revenue', 'gelir']):
        analysis.append("ÄŸÅ¸â€™Â° SatÃ„Â±Ã…Å¸/gelir verileri iÃƒÂ§eriyor.")
    elif any(keyword in ' '.join([word[0] for word in top_words]) for keyword in ['ÃƒÂ§alÃ„Â±Ã…Å¸an', 'employee', 'personel']):
        analysis.append("ÄŸÅ¸â€˜Â¥ Ã„Â°nsan kaynaklarÃ„Â±/personel verisi.")
    else:
        analysis.append("ÄŸÅ¸â€œÅ  Genel veri tablosu Ã…Å¸eklinde dÃƒÂ¼zenlenmiÃ…Å¸.")
    
    # Veri yoÃ„Å¸unluÃ„Å¸u analizi
    if rows < 50:
        analysis.append("ÄŸÅ¸â€œÂ KÃƒÂ¼ÃƒÂ§ÃƒÂ¼k boyutlu, detaylÃ„Â± inceleme iÃƒÂ§in uygun.")
    elif rows < 500:
        analysis.append("ÄŸÅ¸â€œË† Orta boyutlu, analiz iÃƒÂ§in ideal.")
    else:
        analysis.append("ÄŸÅ¸ÂÂ¯ BÃƒÂ¼yÃƒÂ¼k veri seti, filtreleme ÃƒÂ¶nerilir.")
    
    # SÃƒÂ¼tun ÃƒÂ§eÃ…Å¸itliliÃ„Å¸i
    numeric_cols = df.select_dtypes(include=['number']).columns
    text_cols = df.select_dtypes(include=['object']).columns
    
    if len(numeric_cols) > len(text_cols):
        analysis.append("ÄŸÅ¸â€Â¢ Ãƒâ€¡oÃ„Å¸unlukla sayÃ„Â±sal veriler iÃƒÂ§eriyor.")
    elif len(text_cols) > len(numeric_cols):
        analysis.append("ÄŸÅ¸â€œÂ AÃ„Å¸Ã„Â±rlÃ„Â±klÃ„Â± olarak metin verileri var.")
    else:
        analysis.append("Ã¢Å¡â€“Ã¯Â¸Â SayÃ„Â±sal ve metin verileri dengeli daÃ„Å¸Ã„Â±lÃ„Â±m.")
    
    # Veri kalitesi
    empty_ratio = df.isnull().sum().sum() / (rows * cols)
    if empty_ratio < 0.05:
        analysis.append("Ã¢Å“â€¦ Veri kalitesi yÃƒÂ¼ksek, az boÃ…Å¸ hÃƒÂ¼cre.")
    elif empty_ratio < 0.20:
        analysis.append("Ã¢Å¡Â Ã¯Â¸Â Orta dÃƒÂ¼zeyde veri eksikliÃ„Å¸i var.")
    else:
        analysis.append("ÄŸÅ¸â€Â´ Veri kalitesi dÃƒÂ¼Ã…Å¸ÃƒÂ¼k, temizlik gerekli.")
    
    return analysis

def smart_voice_assistant(voice_text, df):
    """AkÃ„Â±llÃ„Â± sesli asistan - Excel verilerini analiz ederek doÃ„Å¸al dil komutlarÃ„Â±nÃ„Â± iÃ…Å¸ler"""
    voice_text = voice_text.lower()
    original_df = df.copy()
    
    # Excel sÃƒÂ¼tun isimlerini ve iÃƒÂ§eriklerini ÃƒÂ¶Ã„Å¸ren
    column_info = {}
    for col in df.columns:
        col_lower = str(col).lower()
        # Her sÃƒÂ¼tundaki benzersiz deÃ„Å¸erleri al (ilk 100 satÃ„Â±r iÃƒÂ§in performans)
        sample_values = df[col].dropna().astype(str).str.lower().head(100).unique()
        column_info[col_lower] = {
            'original_name': col,
            'sample_values': sample_values
        }
    
    # Sayma komutlarÃ„Â±
    count_patterns = ['kaÃƒÂ§', 'sayÃ„Â±', 'adet', 'tane', 'count']
    is_count_query = any(pattern in voice_text for pattern in count_patterns)
    
    # Ã„Â°ÃƒÂ§erik arama komutlarÃ„Â±
    content_patterns = ['iÃƒÂ§er', 'geÃƒÂ§', 'bulunan', 'olan', 'yazan', 'contain']
    is_content_search = any(pattern in voice_text for pattern in content_patterns)
    
    # SÃƒÂ¼tun seÃƒÂ§me komutlarÃ„Â±
    column_patterns = ['sÃƒÂ¼tun', 'sutun', 'kolon', 'alan', 'field']
    is_column_select = any(pattern in voice_text for pattern in column_patterns)
    
    # Anahtar kelimeleri ÃƒÂ§Ã„Â±kar
    words = voice_text.split()
    search_terms = [w for w in words if len(w) > 2 and w not in [
        'iÃƒÂ§er', 'geÃƒÂ§', 'bulunan', 'olan', 'yazan', 'sÃƒÂ¼tun', 'sutun', 'kolon',
        'getir', 'gÃƒÂ¶ster', 'bul', 'ara', 'kayÃ„Â±t', 'veri', 'sadece', 'olan',
        'kaÃƒÂ§', 'tane', 'adet', 'sayÃ„Â±', 'iÃƒÂ§in', 'ile', 'den', 'dan', 'nda', 'nde'
    ]]
    
    # Hangi sÃƒÂ¼tun hedeflendiÃ„Å¸ini bul
    target_column = None
    target_content = None
    
    for term in search_terms:
        # SÃƒÂ¼tun ismi eÃ…Å¸leÃ…Å¸mesi ara
        for col_key, col_data in column_info.items():
            # SÃƒÂ¼tun isminde geÃƒÂ§iyor mu?
            if term in col_key or any(part in term for part in col_key.split()):
                target_column = col_data['original_name']
                break
            
            # SÃƒÂ¼tun iÃƒÂ§eriÃ„Å¸inde geÃƒÂ§iyor mu?
            if any(term in str(val) for val in col_data['sample_values']):
                if not target_column:  # Ã„Â°lk bulunan sÃƒÂ¼tunu al
                    target_column = col_data['original_name']
                target_content = term
                break
    
    # Ãƒâ€“zel komut analizleri
    result_message = ""
    
    try:
        if is_count_query and target_content:
            # "KaÃƒÂ§ tane merhaba yazan veri var" gibi sorular
            if target_column:
                filtered_df = df[df[target_column].astype(str).str.lower().str.contains(target_content, na=False)]
                count = len(filtered_df)
                result_message = f"'{target_content}' kelimesi '{target_column}' sÃƒÂ¼tununda {count} kayÃ„Â±tta bulundu."
                return filtered_df, result_message
            else:
                # TÃƒÂ¼m sÃƒÂ¼tunlarda ara
                mask = df.astype(str).apply(lambda x: x.str.lower().str.contains(target_content, na=False)).any(axis=1)
                filtered_df = df[mask]
                count = len(filtered_df)
                result_message = f"'{target_content}' kelimesi toplam {count} kayÃ„Â±tta bulundu."
                return filtered_df, result_message
        
        elif is_content_search and target_content:
            # "Talep aÃƒÂ§Ã„Â±klamasÃ„Â± iÃƒÂ§erisinde merhaba yazan verileri getir"
            if target_column:
                filtered_df = df[df[target_column].astype(str).str.lower().str.contains(target_content, na=False)]
                result_message = f"'{target_column}' sÃƒÂ¼tununda '{target_content}' iÃƒÂ§eren {len(filtered_df)} kayÃ„Â±t bulundu."
                return filtered_df, result_message
            else:
                # Genel arama
                mask = df.astype(str).apply(lambda x: x.str.lower().str.contains(target_content, na=False)).any(axis=1)
                filtered_df = df[mask]
                result_message = f"'{target_content}' iÃƒÂ§eren {len(filtered_df)} kayÃ„Â±t bulundu."
                return filtered_df, result_message
        
        elif is_column_select and target_column:
            # "Sadece talep aÃƒÂ§Ã„Â±klamasÃ„Â± sÃƒÂ¼tununu gÃƒÂ¶ster"
            filtered_df = df[[target_column]]
            result_message = f"'{target_column}' sÃƒÂ¼tunu gÃƒÂ¶steriliyor."
            return filtered_df, result_message
        
        elif target_column and not is_count_query and not is_content_search:
            # Genel sÃƒÂ¼tun bazlÃ„Â± arama
            if target_content:
                filtered_df = df[df[target_column].astype(str).str.lower().str.contains(target_content, na=False)]
                result_message = f"'{target_column}' sÃƒÂ¼tununda '{target_content}' aramasÃ„Â±: {len(filtered_df)} sonuÃƒÂ§."
                return filtered_df, result_message
            else:
                # Sadece sÃƒÂ¼tunu gÃƒÂ¶ster
                filtered_df = df[[target_column]]
                result_message = f"'{target_column}' sÃƒÂ¼tunu gÃƒÂ¶steriliyor."
                return filtered_df, result_message
        
        # Genel arama (hiÃƒÂ§bir ÃƒÂ¶zel komut yoksa)
        elif search_terms:
            search_term = search_terms[0]
            mask = df.astype(str).apply(lambda x: x.str.lower().str.contains(search_term, na=False)).any(axis=1)
            filtered_df = df[mask]
            result_message = f"'{search_term}' aramasÃ„Â±: {len(filtered_df)} sonuÃƒÂ§ bulundu."
            return filtered_df, result_message
    
    except Exception as e:
        result_message = f"Arama hatasÃ„Â±: {str(e)}"
        return df, result_message
    
    # HiÃƒÂ§bir Ã…Å¸ey bulunamazsa
    result_message = "Komut anlaÃ…Å¸Ã„Â±lamadÃ„Â±. LÃƒÂ¼tfen daha aÃƒÂ§Ã„Â±k ifade edin."
    return df, result_message

def smart_voice_assistant(voice_text, df):
    """GeliÃ…Å¸miÃ…Å¸ AI sesli asistan - Excel sÃƒÂ¼tunlarÃ„Â±nÃ„Â± ve iÃƒÂ§eriklerini analiz ederek akÃ„Â±llÃ„Â± filtreleme yapar"""
    voice_text = voice_text.lower().strip()
    
    # Debug iÃƒÂ§in orijinal metni logla
    print(f"ÄŸÅ¸ÂÂ¤ AlgÃ„Â±lanan ses: '{voice_text}'")
    
    # Mevcut sÃƒÂ¼tun isimlerini analiz et
    column_analysis = {}
    for col in df.columns:
        col_clean = str(col).lower()
        # Her sÃƒÂ¼tundaki eÃ…Å¸siz deÃ„Å¸erleri al (ilk 200 tane - daha fazla veri)
        unique_values = df[col].dropna().astype(str).str.lower().unique()[:200]
        column_analysis[col] = {
            'name_lower': col_clean,
            'original_name': col,
            'sample_values': list(unique_values),
            'value_count': len(df[col].dropna()),
            'dtype': str(df[col].dtype)
        }
    
    # Arama teriminin hangi sÃƒÂ¼tunda bulunduÃ„Å¸unu akÃ„Â±llÃ„Â±ca tespit et
    def find_best_column_for_content(search_terms, df):
        """Arama terimlerinin hangi sÃƒÂ¼tunlarda bulunduÃ„Å¸unu analiz eder"""
        column_scores = {}
        
        for col in df.columns:
            score = 0
            matches = 0
            
            # Her arama terimi iÃƒÂ§in bu sÃƒÂ¼tunda kaÃƒÂ§ eÃ…Å¸leÃ…Å¸me var
            for term in search_terms:
                try:
                    col_matches = df[col].astype(str).str.lower().str.contains(term, na=False, case=False, regex=False).sum()
                    if col_matches > 0:
                        score += col_matches
                        matches += 1
                        print(f"   ÄŸÅ¸â€Â '{term}' -> '{col}' sÃƒÂ¼tununda {col_matches} eÃ…Å¸leÃ…Å¸me")
                except:
                    continue
            
            if score > 0:
                column_scores[col] = {
                    'score': score,
                    'term_matches': matches,
                    'avg_score': score / len(search_terms) if len(search_terms) > 0 else 0
                }
        
        # En iyi sÃƒÂ¼tunu seÃƒÂ§
        if column_scores:
            # Ãƒâ€“ncelik: En ÃƒÂ§ok terimi olan, sonra en yÃƒÂ¼ksek skor
            best_col = max(column_scores.items(), 
                          key=lambda x: (x[1]['term_matches'], x[1]['score']))
            
            print(f"ÄŸÅ¸ÂÂ¯ En iyi sÃƒÂ¼tun: '{best_col[0]}' (Skor: {best_col[1]['score']}, Terim: {best_col[1]['term_matches']})")
            return best_col[0], column_scores
        
        return None, {}
    def find_column_by_name(voice_text):
        # Sadece aÃƒÂ§Ã„Â±k sÃƒÂ¼tun belirteÃƒÂ§leri varsa sÃƒÂ¼tun ara
        explicit_column_indicators = ['sÃƒÂ¼tun', 'sutun', 'sÃƒÂ¼tunu', 'sutunu', 'alanÃ„Â±', 'alanda']
        
        # AÃƒÂ§Ã„Â±k sÃƒÂ¼tun belirteci yoksa tÃƒÂ¼m sÃƒÂ¼tunlarda ara
        if not any(indicator in voice_text for indicator in explicit_column_indicators):
            print(f"ÄŸÅ¸â€Â AÃƒÂ§Ã„Â±k sÃƒÂ¼tun belirteci yok, tÃƒÂ¼m sÃƒÂ¼tunlarda arama yapÃ„Â±lacak")
            return None
        
        # AÃƒÂ§Ã„Â±k sÃƒÂ¼tun belirteci varsa en uygun sÃƒÂ¼tunu bul
        best_match = None
        best_score = 0
        
        for col_info in column_analysis.values():
            col_original = col_info['original_name'].lower()
            col_words = col_original.split()
            
            # Sesli metindeki kelimeleri temizle
            voice_words = voice_text.replace(':', '').replace(',', '').split()
            voice_words = [w for w in voice_words if len(w) > 2]
            
            # SÃƒÂ¼tun ismindeki tÃƒÂ¼m kelimelerin sesli metinde olup olmadÃ„Â±Ã„Å¸Ã„Â±nÃ„Â± kontrol et
            matching_words = 0
            total_char_match = 0
            
            for col_word in col_words:
                # TÃƒÂ¼rkÃƒÂ§e karakter temizliÃ„Å¸i
                col_word_clean = col_word.replace('Ã„Â±', 'i').replace('Ã„Å¸', 'g').replace('ÃƒÂ¼', 'u').replace('Ã…Å¸', 's').replace('ÃƒÂ¶', 'o').replace('ÃƒÂ§', 'c')
                
                for voice_word in voice_words:
                    voice_word_clean = voice_word.replace('Ã„Â±', 'i').replace('Ã„Å¸', 'g').replace('ÃƒÂ¼', 'u').replace('Ã…Å¸', 's').replace('ÃƒÂ¶', 'o').replace('ÃƒÂ§', 'c')
                    
                    # KÃ„Â±smi eÃ…Å¸leÃ…Å¸me de kabul et
                    if col_word_clean in voice_word_clean or voice_word_clean in col_word_clean:
                        matching_words += 1
                        total_char_match += len(col_word)
                        break
            
            # EÃ…Å¸leÃ…Å¸me skorunu hesapla
            if len(col_words) > 0:
                score = (matching_words / len(col_words)) * total_char_match
                
                # Ãƒâ€“zel kelimeler iÃƒÂ§in bonus puan
                if any(keyword in voice_text for keyword in ['unvan', 'fiili', 'adÃ„Â±', 'adi']):
                    if any(keyword in col_original for keyword in ['unvan', 'fiili', 'ad']):
                        score += 100  # YÃƒÂ¼ksek bonus
                
                if score > best_score:
                    best_score = score
                    best_match = col_info['original_name']
        
        print(f"ÄŸÅ¸ÂÂ¯ En iyi sÃƒÂ¼tun eÃ…Å¸leÃ…Å¸mesi: {best_match} (Skor: {best_score})")
        
        # Yeterli skor yoksa tÃƒÂ¼m sÃƒÂ¼tunlarda ara
        if best_score < 50:
            print(f"ÄŸÅ¸â€Â Skor yetersiz ({best_score}), tÃƒÂ¼m sÃƒÂ¼tunlarda arama yapÃ„Â±lacak")
            return None
        
        return best_match
    
    # Ã„Â°ÃƒÂ§erik kelimelerini ayÃ„Â±kla
    def extract_search_content(voice_text, detected_column=None):
        # Bu kelimeleri atla
        skip_words = {
            'tabloda', 'tablodan', 'kayÃ„Â±t', 'kayÃ„Â±tlarÃ„Â±', 'kayÃ„Â±tlar', 'veri', 'veriler',
            'getir', 'gÃƒÂ¶ster', 'bul', 'ara', 'filtrele', 'iÃƒÂ§eren', 'olan', 'olanlarÃ„Â±',
            'yazan', 'yazanlarÃ„Â±', 'bulunan', 'bulunanlarÃ„Â±', 'sÃƒÂ¼tun', 'sutun', 'sadece', 
            'iÃƒÂ§in', 'ile', 'den', 'dan', 'nda', 'nde', 'da', 'de', 'adi:', 'adÃ„Â±:', 'olan'
        }
        
        # EÃ„Å¸er sÃƒÂ¼tun tespit edildiyse, o sÃƒÂ¼tunun kelimelerini de atla
        if detected_column:
            column_words = detected_column.lower().split()
            skip_words.update(column_words)
            # TÃƒÂ¼rkÃƒÂ§e karakter varyasyonlarÃ„Â±
            for word in column_words:
                skip_words.add(word.replace('Ã„Â±', 'i').replace('Ã„Å¸', 'g').replace('ÃƒÂ¼', 'u').replace('Ã…Å¸', 's').replace('ÃƒÂ¶', 'o').replace('ÃƒÂ§', 'c'))
        
        words = voice_text.replace(':', '').replace(',', '').split()
        content_words = []
        
        for word in words:
            word_clean = word.lower().strip()
            if len(word_clean) > 2 and word_clean not in skip_words:
                # Ãƒâ€“zel isimler ve ÃƒÂ¶nemli kelimeler
                if any(char.isupper() for char in word) or word_clean in ['genel', 'mÃƒÂ¼dÃƒÂ¼r', 'yardÃ„Â±mcÃ„Â±sÃ„Â±', 'baÃ…Å¸kan', 'uzman']:
                    content_words.append(word_clean)
                elif not any(skip in word_clean for skip in skip_words):
                    content_words.append(word_clean)
        
        print(f"ÄŸÅ¸â€œÂ Ãƒâ€¡Ã„Â±karÃ„Â±lan arama kelimeleri: {content_words}")
        return content_words
    
    # Komut tÃƒÂ¼rÃƒÂ¼nÃƒÂ¼ belirle ve iÃ…Å¸le
    result_message = ""
    
    # 0. Ãƒâ€“NCE SAYISAL KARÃ…ÂILAÃ…ÂTIRMA KOMUTLARÃ„Â°NI KONTROL ET (en yÃƒÂ¼ksek ÃƒÂ¶ncelik)
    comparison_patterns = {
        'kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k': ['kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k', 'kucuk', 'az', 'altÃ„Â±nda', 'altÃ„Â±ndaki', 'dan kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k', 'den kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k'],
        'bÃƒÂ¼yÃƒÂ¼k': ['bÃƒÂ¼yÃƒÂ¼k', 'buyuk', 'fazla', 'ÃƒÂ¼stÃƒÂ¼nde', 'ÃƒÂ¼stÃƒÂ¼ndeki', 'dan bÃƒÂ¼yÃƒÂ¼k', 'den bÃƒÂ¼yÃƒÂ¼k', 'dan fazla'],
        'eÃ…Å¸it': ['eÃ…Å¸it', 'esit', 'olan', 'equal']
    }
    
    # SayÃ„Â± arama
    number_match = re.search(r'(\d+)', voice_text)
    comparison_type = None
    
    if number_match:
        target_number = int(number_match.group(1))
        
        # KarÃ…Å¸Ã„Â±laÃ…Å¸tÃ„Â±rma tÃƒÂ¼rÃƒÂ¼nÃƒÂ¼ bul
        for comp_type, patterns in comparison_patterns.items():
            if any(pattern in voice_text for pattern in patterns):
                comparison_type = comp_type
                break
        
        if comparison_type:
            # SÃƒÂ¼tun adÃ„Â±nÃ„Â± bul
            target_column = find_column_by_name(voice_text)
            
            if not target_column:
                # SayÃ„Â±sal sÃƒÂ¼tunlarÃ„Â± kontrol et
                numeric_cols = df.select_dtypes(include=['number']).columns
                for col in numeric_cols:
                    col_lower = col.lower()
                    if any(word in col_lower for word in voice_text.split() if len(word) > 2):
                        target_column = col
                        break
                
                # Hala bulunamadÃ„Â±ysa ilk sayÃ„Â±sal sÃƒÂ¼tunu al
                if not target_column and len(numeric_cols) > 0:
                    target_column = numeric_cols[0]
            
            if target_column:
                try:
                    # SayÃ„Â±sal deÃ„Å¸erlere dÃƒÂ¶nÃƒÂ¼Ã…Å¸tÃƒÂ¼r
                    df_numeric = pd.to_numeric(df[target_column], errors='coerce')
                    
                    if comparison_type == 'kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k':
                        mask = df_numeric < target_number
                        result_message = f"ÄŸÅ¸â€œÅ  '{target_column}' sÃƒÂ¼tununda {target_number}'dan kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k olan {mask.sum()} kayÃ„Â±t bulundu"
                    elif comparison_type == 'bÃƒÂ¼yÃƒÂ¼k':
                        mask = df_numeric > target_number
                        result_message = f"ÄŸÅ¸â€œÅ  '{target_column}' sÃƒÂ¼tununda {target_number}'dan bÃƒÂ¼yÃƒÂ¼k olan {mask.sum()} kayÃ„Â±t bulundu"
                    elif comparison_type == 'eÃ…Å¸it':
                        mask = df_numeric == target_number
                        result_message = f"ÄŸÅ¸â€œÅ  '{target_column}' sÃƒÂ¼tununda {target_number}'a eÃ…Å¸it olan {mask.sum()} kayÃ„Â±t bulundu"
                    
                    filtered_df = df[mask]
                    print(f"ÄŸÅ¸â€Â¢ SayÃ„Â±sal filtreleme: '{target_column}' {comparison_type} {target_number} -> {mask.sum()} sonuÃƒÂ§")
                    return filtered_df, result_message
                    
                except Exception as e:
                    print(f"Ã¢Å¡Â Ã¯Â¸Â SayÃ„Â±sal karÃ…Å¸Ã„Â±laÃ…Å¸tÃ„Â±rma hatasÃ„Â±: {e}")

    # 1. Ãƒâ€“NCE KAYIT LÃ„Â°MÃ„Â°TLEME KOMUTLARÃ„Â°NI KONTROL ET (en yÃƒÂ¼ksek ÃƒÂ¶ncelik)
    if any(word in voice_text for word in ['ilk', 'son']) and any(word in voice_text for word in ['kayÃ„Â±t', 'satÃ„Â±r']) and 'sÃƒÂ¼tun' not in voice_text:
        number_match = re.search(r'(\d+)', voice_text)
        if number_match:
            n = int(number_match.group(1))
            
            if 'ilk' in voice_text:
                filtered_df = df.head(n)
                result_message = f"ÄŸÅ¸â€œâ€¹ Ã„Â°lk {n} kayÃ„Â±t getiriliyor"
                return filtered_df, result_message
            elif 'son' in voice_text:
                filtered_df = df.tail(n)
                result_message = f"  Son {n} kayÃ„Â±t getiriliyor"
                return filtered_df, result_message
    
    # 1. AKILLI Ã„Â°Ãƒâ€¡ERÃ„Â°K ARAMA ("mÃƒÂ¼fettiÃ…Å¸ olanlarÃ„Â± getir", "sadece mÃƒÂ¼fettiÃ…Å¸")
    if any(word in voice_text for word in ['getir', 'gÃƒÂ¶ster', 'bul', 'ara', 'filtrele', 'olanlarÃ„Â±', 'yazanlarÃ„Â±', 'iÃƒÂ§eren', 'sadece', 'olan']):
        # Ãƒâ€“nce sÃƒÂ¼tun belirteci var mÃ„Â± kontrol et
        target_column = find_column_by_name(voice_text)
        search_content = extract_search_content(voice_text, target_column)
        
        print(f"ÄŸÅ¸â€Â Manuel hedef sÃƒÂ¼tun: {target_column}")
        print(f"ÄŸÅ¸â€Â Arama iÃƒÂ§eriÃ„Å¸i: {search_content}")
        
        if search_content:
            # Arama terimlerini hazÃ„Â±rla
            search_terms = search_content if isinstance(search_content, list) else [search_content]
            
            if target_column:
                # Manuel olarak belirtilmiÃ…Å¸ sÃƒÂ¼tunda ara
                print(f"ÄŸÅ¸ÂÂ¯ Manuel belirtilen '{target_column}' sÃƒÂ¼tununda arama yapÃ„Â±lÃ„Â±yor...")
                search_term = ' '.join(search_terms) if len(search_terms) > 1 else search_terms[0]
                mask = df[target_column].astype(str).str.lower().str.contains(search_term, na=False, case=False, regex=False)
                filtered_df = df[mask]
                matches = mask.sum()
                print(f"   ÄŸÅ¸â€œÂ '{search_term}' terimi '{target_column}' sÃƒÂ¼tununda {matches} kayÃ„Â±t buldu")
                result_message = f"ÄŸÅ¸â€Â '{target_column}' sÃƒÂ¼tununda '{search_term}' iÃƒÂ§eren {matches} kayÃ„Â±t bulundu"
                return filtered_df, result_message
            else:
                # AkÃ„Â±llÃ„Â± sÃƒÂ¼tun analizi yap - hangi sÃƒÂ¼tunda bu terimler en ÃƒÂ§ok geÃƒÂ§iyor?
                print(f"ÄŸÅ¸Â§Â  Arama terimleri iÃƒÂ§in en uygun sÃƒÂ¼tun analiz ediliyor...")
                best_column, column_scores = find_best_column_for_content(search_terms, df)
                
                if best_column and column_scores[best_column]['score'] >= len(search_terms):
                    # Belirli bir sÃƒÂ¼tunda yoÃ„Å¸unlaÃ…Å¸mÃ„Â±Ã…Å¸ - o sÃƒÂ¼tunda ara
                    search_term = ' '.join(search_terms) if len(search_terms) > 1 else search_terms[0]
                    mask = df[best_column].astype(str).str.lower().str.contains(search_term, na=False, case=False, regex=False)
                    filtered_df = df[mask]
                    matches = mask.sum()
                    result_message = f"ÄŸÅ¸ÂÂ¯ '{search_term}' iÃƒÂ§in en uygun sÃƒÂ¼tun '{best_column}' - {matches} kayÃ„Â±t bulundu"
                    return filtered_df, result_message
                else:
                    # HiÃƒÂ§bir sÃƒÂ¼tunda yoÃ„Å¸unlaÃ…Å¸mamÃ„Â±Ã…Å¸ - tÃƒÂ¼m sÃƒÂ¼tunlarda ara
                    print(f"ÄŸÅ¸â€Â TÃƒÂ¼m sÃƒÂ¼tunlarda arama yapÃ„Â±lÃ„Â±yor ({len(df.columns)} sÃƒÂ¼tun)...")
                    search_term = ' '.join(search_terms) if len(search_terms) > 1 else search_terms[0]
                    mask = pd.Series([False] * len(df))
                    matching_columns = []
                
                for col in df.columns:
                    try:
                        col_mask = df[col].astype(str).str.lower().str.contains(search_term, na=False, case=False, regex=False)
                        col_matches = col_mask.sum()
                        if col_matches > 0:
                            mask = mask | col_mask
                            matching_columns.append(col)
                            print(f"   ÄŸÅ¸â€œÂ '{search_term}' terimi '{col}' sÃƒÂ¼tununda {col_matches} kayÃ„Â±t buldu")
                    except Exception as e:
                        print(f"   Ã¢Å¡Â Ã¯Â¸Â '{col}' sÃƒÂ¼tununda arama hatasÃ„Â±: {e}")
                        continue
                
                if mask.sum() > 0:
                    filtered_df = df[mask]
                    result_message = f"  '{search_term}' iÃƒÂ§eren {len(filtered_df)} kayÃ„Â±t bulundu"
                    if matching_columns:
                        result_message += f" (Bulunan sÃƒÂ¼tunlar: {', '.join(matching_columns[:3])})"
                    return filtered_df, result_message
                else:
                    result_message = f"Ã¢ÂÅ’ '{search_term}' iÃƒÂ§in hiÃƒÂ§bir eÃ…Å¸leÃ…Å¸me bulunamadÃ„Â±"
                    return df, result_message
    
    # 2. Ã„Â°STATÃ„Â°STÃ„Â°K KOMUTLARÃ„Â°
    elif any(word in voice_text for word in ['ortalama', 'average', 'mean']):
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            col = numeric_cols[0]
            avg_val = df[col].mean()
            result_message = f"ÄŸÅ¸â€œÅ  '{col}' sÃƒÂ¼tununun ortalamasÃ„Â±: {avg_val:.2f}"
            return df, result_message
    
    elif any(word in voice_text for word in ['en yÃƒÂ¼ksek', 'maksimum', 'max', 'bÃƒÂ¼yÃƒÂ¼k']):
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            col = numeric_cols[0]
            max_val = df[col].max()
            result_message = f"  '{col}' sÃƒÂ¼tununun en yÃƒÂ¼ksek deÃ„Å¸eri: {max_val}"
            return df, result_message
    
    elif any(word in voice_text for word in ['toplam kayÃ„Â±t', 'kaÃƒÂ§ kayÃ„Â±t', 'satÃ„Â±r sayÃ„Â±sÃ„Â±']):
        result_message = f"ÄŸÅ¸â€œâ€¹ Toplam kayÃ„Â±t sayÃ„Â±sÃ„Â±: {len(df)}"
        return df, result_message
    
    elif any(word in voice_text for word in ['benzersiz', 'unique', 'farklÃ„Â±']):
        # Ã„Â°lgili sÃƒÂ¼tunu bul
        target_col = find_column_by_name(voice_text)
        
        if target_col:
            unique_count = df[target_col].nunique()
            result_message = f"ÄŸÅ¸â€Â¢ '{target_col}' sÃƒÂ¼tununda {unique_count} benzersiz deÃ„Å¸er var"
            return df, result_message
    
    # 3. SAYMA KOMUTLARÃ„Â° ("kaÃƒÂ§ tane", "sayÃ„Â±sÃ„Â±", "adet")
    elif any(word in voice_text for word in ['kaÃƒÂ§', 'sayÃ„Â±', 'adet', 'toplam']):
        search_content = extract_search_content(voice_text)
        
        if search_content:
            search_term = search_content[0]
            target_column = find_column_by_name(voice_text)
            
            if target_column:
                # Belirli sÃƒÂ¼tunda say
                matching_rows = df[target_column].astype(str).str.lower().str.contains(search_term, na=False, case=False, regex=False)
                count = matching_rows.sum()
                result_message = f"ÄŸÅ¸â€Â¢ '{search_term}' kelimesi '{target_column}' sÃƒÂ¼tununda {count} kayÃ„Â±tta bulundu"
            else:
                # TÃƒÂ¼m sÃƒÂ¼tunlarda say
                mask = df.astype(str).apply(lambda x: x.str.lower().str.contains(search_term, na=False, case=False)).any(axis=1)
                count = mask.sum()
                result_message = f"  '{search_term}' kelimesi toplam {count} kayÃ„Â±tta bulundu"
            
            return df, result_message
    
    # 4. SÃƒÅ“TUN SEÃƒâ€¡Ã„Â°MÃ„Â° ("sÃƒÂ¼tunu gÃƒÂ¶ster", "sadece ... sÃƒÂ¼tun")
    elif any(word in voice_text for word in ['sÃƒÂ¼tun', 'sutun', 'sadece']):
        best_match = None
        best_score = 0
        
        # Ãƒâ€“zel sÃƒÂ¼tun seÃƒÂ§imleri - Ã„Â°lk N sÃƒÂ¼tun
        if 'ilk' in voice_text and 'sÃƒÂ¼tun' in voice_text:
            number_match = re.search(r'(\d+)', voice_text)
            if number_match:
                n = int(number_match.group(1))
                selected_cols = df.columns[:n]
                result_message = f"ÄŸÅ¸â€œâ€¹ Ã„Â°lk {n} sÃƒÂ¼tun seÃƒÂ§ildi"
                return df[selected_cols], result_message
        
        # AkÃ„Â±llÃ„Â± sÃƒÂ¼tun eÃ…Å¸leÃ…Å¸tirme
        target_column = find_column_by_name(voice_text)
        if target_column:
            result_message = f"  '{target_column}' sÃƒÂ¼tunu seÃƒÂ§ildi"
            return df[[target_column]], result_message
    
    # 5. GENEL ARAMA - basitleÃ…Å¸tirilmiÃ…Å¸
    else:
        search_content = extract_search_content(voice_text)
        if search_content:
            search_term = search_content[0]
            
            # TÃƒÂ¼m sÃƒÂ¼tunlarda ara
            mask = pd.Series([False] * len(df))
            matching_columns = []
            
            for col in df.columns:
                col_mask = df[col].astype(str).str.lower().str.contains(search_term, na=False, case=False, regex=False)
                if col_mask.sum() > 0:
                    mask = mask | col_mask
                    matching_columns.append(col)
            
            if mask.sum() > 0:
                filtered_df = df[mask]
                result_message = f"ÄŸÅ¸â€Â '{search_term}' iÃƒÂ§in {len(filtered_df)} kayÃ„Â±t bulundu"
                if matching_columns:
                    result_message += f" (SÃƒÂ¼tunlar: {', '.join(matching_columns[:3])})"
                return filtered_df, result_message
    
    result_message = f"Ã¢Ââ€œ Komut anlaÃ…Å¸Ã„Â±lamadÃ„Â±: '{voice_text}'. LÃƒÂ¼tfen daha net konuÃ…Å¸un."
    return df, result_message

def process_voice_search(voice_text, df):
    """Sesli arama metnini akÃ„Â±llÃ„Â± asistana yÃƒÂ¶nlendirir"""
    filtered_df, message = smart_voice_assistant(voice_text, df)
    
    # Session state'e mesajÃ„Â± kaydet
    if 'voice_result_message' not in st.session_state:
        st.session_state['voice_result_message'] = ""
    
    st.session_state['voice_result_message'] = message
    return filtered_df

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # BaÃ…Å¸lÃ„Â±klarÃ„Â± temizle
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # OlasÃ„Â± varyasyonlarÃ„Â± eÃ…Å¸leÃ…Å¸tir
    aliases = {
        "Talep No": {"Talep No", "Talep_No", "TalepNo", "ID", "No"},
        "Talep AÃƒÂ§Ã„Â±klamasÃ„Â±": {"Talep AÃƒÂ§Ã„Â±klamasÃ„Â±", "Talep Aciklamasi", "Aciklama", "AÃƒÂ§Ã„Â±klama", "Talep AÃƒÂ§Ã„Â±klama"},
        "YanÃ„Â±t": {"YanÃ„Â±t", "Yanit", "Cevap", "SonuÃƒÂ§"},
        "YanÃ„Â±t AÃƒÂ§Ã„Â±klamasÃ„Â±": {"YanÃ„Â±t AÃƒÂ§Ã„Â±klamasÃ„Â±", "Yanit Aciklamasi", "Cevap AÃƒÂ§Ã„Â±klamasÃ„Â±", "Detay", "AÃƒÂ§Ã„Â±klama (YanÃ„Â±t)"},
    }

    colmap = {}
    for target, names in aliases.items():
        for c in df.columns:
            if c in names or c.lower() in {n.lower() for n in names}:
                colmap[c] = target
                break

    df = df.rename(columns=colmap)
    return df

def text_search_mask(df: pd.DataFrame, cols, query: str, whole_word: bool, case_sensitive: bool):
    if not query:
        return pd.Series([True] * len(df), index=df.index)

    # Basit string arama - yazdÃ„Â±Ã„Å¸Ã„Â±nÃ„Â±z metni olduÃ„Å¸u gibi arar
    mask = pd.Series([False] * len(df), index=df.index)
    
    for c in cols:
        if c in df.columns:
            colvals = df[c].astype(str).fillna("")
            
            if case_sensitive:
                # BÃƒÂ¼yÃƒÂ¼k/kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k harf duyarlÃ„Â± arama
                if whole_word:
                    # Tam kelime eÃ…Å¸leÃ…Å¸mesi (regex ile)
                    pattern = r"\b" + re.escape(query) + r"\b"
                    mask = mask | colvals.str.contains(pattern, regex=True, case=True)
                else:
                    # Basit string iÃƒÂ§erme kontrolÃƒÂ¼
                    mask = mask | colvals.str.contains(query, case=True, regex=False)
            else:
                # BÃƒÂ¼yÃƒÂ¼k/kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k harf duyarsÃ„Â±z arama
                if whole_word:
                    # Tam kelime eÃ…Å¸leÃ…Å¸mesi (regex ile)
                    pattern = r"\b" + re.escape(query) + r"\b"
                    mask = mask | colvals.str.contains(pattern, regex=True, case=False)
                else:
                    # Basit string iÃƒÂ§erme kontrolÃƒÂ¼ (varsayÃ„Â±lan)
                    mask = mask | colvals.str.contains(query, case=False, regex=False)
    
    return mask

def highlight_terms(val, terms):
    # Vurgulama devre dÃ„Â±Ã…Å¸Ã„Â± - sadece orijinal deÃ„Å¸eri dÃƒÂ¶ndÃƒÂ¼r
    return val

def to_excel_bytes(df: pd.DataFrame) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="SonuÃƒÂ§lar")
    return output.getvalue()

# -------------------------
# ÄŸÅ¸Å¡â‚¬ MODERN ENTERPRISE HEADER
# -------------------------
st.markdown("""
<style>
.main-header {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 15px;
    margin-bottom: 2rem;
    color: white;
    text-align: center;
}
.feature-badge {
    display: inline-block;
    background: rgba(255, 255, 255, 0.2);
    padding: 0.3rem 0.8rem;
    border-radius: 20px;
    margin: 0.2rem;
    font-size: 0.8rem;
}
.quality-score {
    font-size: 2rem;
    font-weight: bold;
    margin: 1rem 0;
}
.performance-indicator {
    background: rgba(255, 255, 255, 0.1);
    padding: 1rem;
    border-radius: 10px;
    margin: 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<div class="main-header">
    <h1>ğŸš€ Enterprise Excel GÃ¶rÃ¼ntÃ¼leyici</h1>
    <p>AI Destekli â€¢ Performance Monitoring â€¢ Smart Analytics</p>
    <div>
        <span class="feature-badge">ÄŸÅ¸Â§Â  AI Powered</span>
        <span class="feature-badge">Ã¢Å¡Â¡ High Performance</span>
        <span class="feature-badge">ÄŸÅ¸â€Â Smart Search</span>
        <span class="feature-badge">ÄŸÅ¸â€œÅ  Advanced Analytics</span>
    </div>
</div>
""", unsafe_allow_html=True)

# -------------------------
# Dosya YÃƒÂ¼kleme ve Validation
# -------------------------

# EÃ„Å¸er streamlit run ile ÃƒÂ§alÃ„Â±Ã…Å¸tÃ„Â±rÃ„Â±lÃ„Â±yorsa dosya yÃƒÂ¼kleme, yoksa doÃ„Å¸rudan dosyadan oku

uploaded = st.file_uploader("ÄŸÅ¸â€œÂ Excel dosyanÃ„Â±zÃ„Â± yÃƒÂ¼kleyin (.xlsx)", type=["xlsx"], key="excel_uploader")
if uploaded is not None:
    # Performance tracking iÃƒÂ§in
    with st.session_state.perf_monitor.track_operation("file_upload"):
        try:
            # DosyayÃ„Â± uploads klasÃƒÂ¶rÃƒÂ¼ne kaydet
            file_path = os.path.join(uploads_path, uploaded.name)
            with open(file_path, "wb") as f:
                f.write(uploaded.getbuffer())
            st.success(f"Ã¢Å“â€¦ Dosya baÃ…Å¸arÃ„Â±yla yÃƒÂ¼klendi: {uploaded.name}")
            st.session_state["selected_file_key"] = uploaded.name
        except Exception as e:
            error_handler.display_error(e, "Dosya yÃƒÂ¼kleme sÃ„Â±rasÃ„Â±nda")

# Dosya yÃƒÂ¼kleme mantÃ„Â±Ã„Å¸Ã„Â± - seÃƒÂ§ilen dosya veya yeni yÃƒÂ¼klenen dosya
selected_file_to_load = st.session_state.get("selected_file_key") or selected_file

if selected_file_to_load:
    # Start performance monitoring
    load_operation = st.session_state.perf_monitor.start_operation("file_load")
    
    with st.spinner(f"{selected_file_to_load} dosyasÃ„Â± yÃƒÂ¼kleniyor..."):
        try:
            df_raw = pd.read_excel(os.path.join(uploads_path, selected_file_to_load))
            
            # Validate the loaded data
            validation_result = data_validator.validate_excel_file(df_raw)
            
            # Show validation results
            if not validation_result['is_valid']:
                st.warning("Ã¢Å¡Â Ã¯Â¸Â Veri kalitesi sorunlarÃ„Â± tespit edildi:")
                for issue in validation_result['issues']:
                    st.write(f"Ã¢â‚¬Â¢ {issue}")
                
                if validation_result['recommendations']:
                    with st.expander("ÄŸÅ¸â€™Â¡ Ã„Â°yileÃ…Å¸tirme Ãƒâ€“nerileri"):
                        for rec in validation_result['recommendations']:
                            st.info(rec)
            
            # Show quality score
            score = validation_result['quality_score']
            score_color = "ÄŸÅ¸Å¸Â¢" if score > 80 else "ÄŸÅ¸Å¸Â¡" if score > 60 else "ÄŸÅ¸â€Â´"
            
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.markdown(f"""
                <div class="performance-indicator">
                    <h3>{score_color} Veri Kalite Skoru</h3>
                    <div class="quality-score">{score:.1f}/100</div>
                </div>
                """, unsafe_allow_html=True)
            
            # End performance monitoring
            st.session_state.perf_monitor.end_operation(load_operation, True)
            
        except Exception as e:
            st.session_state.perf_monitor.end_operation(load_operation, False)
            error_handler.display_error(e, "Dosya okuma sÃ„Â±rasÃ„Â±nda")
            st.stop()

    # -------------------------
    # MAIN APPLICATION TABS
    # -------------------------
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ÄŸÅ¸â€œÅ  Veri Analizi", "ÄŸÅ¸â€œË† AkÃ„Â±llÃ„Â± Analitik", "ÄŸÅ¸â€Â KeÃ…Å¸if & Filtreler", "Ã¢Â­Â Favorilerim", "Ã¢Å¡Â¡ Performans"])

    with tab1:
        st.subheader("ÄŸÅ¸â€œÅ  Veri GÃƒÂ¶rselleÃ…Å¸tirme ve Temel Analiz")
    
    # Show data summary first
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Toplam SatÃ„Â±r", len(df_raw))
    with col2:
        st.metric("SÃƒÂ¼tun SayÃ„Â±sÃ„Â±", len(df_raw.columns))
    with col3:
        memory_usage = df_raw.memory_usage(deep=True).sum() / 1024**2
        st.metric("Bellek KullanÃ„Â±mÃ„Â±", f"{memory_usage:.1f} MB")
    with col4:
        null_percentage = (df_raw.isnull().sum().sum() / (len(df_raw) * len(df_raw.columns))) * 100
        st.metric("BoÃ…Å¸ Veri %", f"{null_percentage:.1f}%")

    # Normalized df for processing
    df = normalize_columns(df_raw)

    # -------------------------
    # ÄŸÅ¸Â¤â€“ AkÃ„Â±llÃ„Â± Ãƒâ€“zet
    # -------------------------
    with st.expander("ÄŸÅ¸Â¤â€“ AkÃ„Â±llÃ„Â± Dosya Ãƒâ€“zeti", expanded=False):
        summary = generate_smart_summary(df)
        
        # ÄŸÅ¸Â¤â€“ AI Analizi
        st.subheader("ÄŸÅ¸Â§Â  AI Analizi")
        for analysis_point in summary['akilli_analiz']:
            st.write(f"Ã¢â‚¬Â¢ {analysis_point}")
        
        st.markdown("---")
        
        # KÃ„Â±sa ÃƒÂ¶zet
        st.write(f"ÄŸÅ¸â€œâ€ **{summary['toplam_satir']} satÃ„Â±r, {summary['toplam_sutun']} sÃƒÂ¼tunlu** bir Excel dosyasÃ„Â± analiz edildi.")
        
        if summary['bos_hucre'] > 0:
            st.write(f"Ã¢Å¡Â Ã¯Â¸Â {summary['bos_hucre']} boÃ…Å¸ hÃƒÂ¼cre tespit edildi.")
        
        # En sÃ„Â±k kelimeler
        if summary['en_sik_kelimeler']:
            st.write("**ÄŸÅ¸â€Â¤ En sÃ„Â±k kullanÃ„Â±lan kelimeler:**")
            for word, count in summary['en_sik_kelimeler']:
                st.write(f"Ã¢â‚¬Â¢ {word.title()}: {count} kez")
        
        # Ãƒâ€“neriler
        if summary['oneriler']:
            st.write("**ÄŸÅ¸â€™Â¡ AkÃ„Â±llÃ„Â± Ãƒâ€“neriler:**")
            for suggestion in summary['oneriler']:
                st.info(suggestion)

    required_cols = ["Talep No", "Talep AÃƒÂ§Ã„Â±klamasÃ„Â±", "YanÃ„Â±t", "YanÃ„Â±t AÃƒÂ§Ã„Â±klamasÃ„Â±"]
    missing = [c for c in required_cols if c not in df.columns]

    with st.expander("ÄŸÅ¸â€œâ€˜ SÃƒÂ¼tun EÃ…Å¸leÃ…Å¸tirme / Bilgi", expanded=False):
        st.write("AlgÃ„Â±lanan sÃƒÂ¼tunlar:", list(df.columns))
        if missing:
            st.warning(
                f"Eksik olduÃ„Å¸u tespit edilen beklenen sÃƒÂ¼tunlar: {missing}. "
                "Yine de mevcut sÃƒÂ¼tunlarla ÃƒÂ§alÃ„Â±Ã…Å¸maya devam edebilirsiniz."
            )
    
    # Smart pagination for large datasets - TAB 1 DATA DISPLAY
    st.markdown("### ÄŸÅ¸â€œÅ  Veri GÃƒÂ¶rÃƒÂ¼ntÃƒÂ¼leme")
    
    # Apply any sidebar filters first
    filtered_df = df.copy()
    
    if len(filtered_df) > 1000:
        st.info(f"ÄŸÅ¸â€œÅ  BÃƒÂ¼yÃƒÂ¼k veri seti tespit edildi ({len(filtered_df):,} satÃ„Â±r). Performans iÃƒÂ§in sayfalama aktif.")
        
        col1, col2, col3 = st.columns([2, 2, 2])
        with col1:
            page_size = st.selectbox("ÄŸÅ¸â€œâ€ Sayfa boyutu", [100, 500, 1000, 2000], index=1, key="tab1_pagesize")
        with col2:
            total_pages = math.ceil(len(filtered_df) / page_size)
            current_page = st.number_input("ÄŸÅ¸â€œÂ Sayfa", min_value=1, max_value=total_pages, value=1, key="tab1_page")
        with col3:
            st.metric("ÄŸÅ¸â€œÅ  Toplam Sayfa", total_pages)
        
        start_idx = (current_page - 1) * page_size
        end_idx = min(start_idx + page_size, len(filtered_df))
        df_display = filtered_df.iloc[start_idx:end_idx]
        
        st.info(f"ÄŸÅ¸â€œâ€ GÃƒÂ¶sterilen: {start_idx + 1}-{end_idx} / {len(filtered_df):,} satÃ„Â±r (Sayfa {current_page}/{total_pages})")
    else:
        df_display = filtered_df
        st.success(f"Ã¢Å“â€¦ TÃƒÂ¼m veriler gÃƒÂ¶steriliyor ({len(df_display):,} satÃ„Â±r)")
    
    # Display the data with smart formatting
    st.dataframe(
        df_display, 
        use_container_width=True, 
        height=400,
        column_config={
            col: st.column_config.TextColumn(
                width="medium" if len(str(df_display[col].iloc[0] if len(df_display) > 0 else "")) < 50 else "large"
            ) for col in df_display.columns
        }
    )
    
    # Export options with performance tracking
    st.markdown("### ÄŸÅ¸â€œÂ¥ Export SeÃƒÂ§enekleri")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ÄŸÅ¸â€œÂ¥ CSV Ã„Â°ndir"):
            with st.session_state.perf_monitor.track_operation("csv_export"):
                csv = filtered_df.to_csv(index=False)
                st.download_button(
                    "Ã¢Â¬â€¡Ã¯Â¸Â CSV DosyasÃ„Â±nÃ„Â± Ã„Â°ndir", 
                    csv, 
                    f"data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
                    "text/csv"
                )
    
    with col2:
        if st.button("ÄŸÅ¸â€œÂ¥ Excel Ã„Â°ndir"):
            with st.session_state.perf_monitor.track_operation("excel_export"):
                excel_buffer = io.BytesIO()
                filtered_df.to_excel(excel_buffer, index=False)
                st.download_button(
                    "Ã¢Â¬â€¡Ã¯Â¸Â Excel DosyasÃ„Â±nÃ„Â± Ã„Â°ndir", 
                    excel_buffer.getvalue(), 
                    f"data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                )
    
    with col3:
        if st.button("ÄŸÅ¸â€œÂ¥ JSON Ã„Â°ndir"):
            with st.session_state.perf_monitor.track_operation("json_export"):
                json_str = filtered_df.to_json(indent=2, orient='records')
                st.download_button(
                    "Ã¢Â¬â€¡Ã¯Â¸Â JSON DosyasÃ„Â±nÃ„Â± Ã„Â°ndir", 
                    json_str, 
                    f"data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 
                    "application/json"
                )
    
    with col4:
        st.metric("ÄŸÅ¸â€œÅ  Export HazÃ„Â±r", f"{len(filtered_df):,} satÃ„Â±r")
    
    # -------------------------
    # ÄŸÅ¸â€œâ€ KART GÃƒâ€“RÃƒÅ“NÃƒÅ“MÃƒÅ“ (Orijinal Ãƒâ€“zellik)
    # -------------------------
    st.markdown("### ÄŸÅ¸â€œâ€ KayÃ„Â±t KartlarÃ„Â± GÃƒÂ¶rÃƒÂ¼nÃƒÂ¼mÃƒÂ¼")
    
    # Toggle between table and card view
    view_col1, view_col2 = st.columns([1, 3])
    with view_col1:
        view_mode = st.selectbox("ÄŸÅ¸â€˜ÂÃ¯Â¸Â GÃƒÂ¶rÃƒÂ¼nÃƒÂ¼m Modu", ["ÄŸÅ¸â€œÅ  Tablo", "ÄŸÅ¸â€œâ€ Kart"], index=1)
    
    if view_mode == "ÄŸÅ¸â€œâ€ Kart":
        # Pagination for cards
        cards_per_page = st.slider("ÄŸÅ¸â€œâ€ Sayfa baÃ…Å¸Ã„Â±na kart sayÃ„Â±sÃ„Â±", 5, 20, 10)
        total_card_pages = math.ceil(len(df_display) / cards_per_page)
        
        if total_card_pages > 1:
            card_page = st.number_input("ÄŸÅ¸â€œâ€ Kart SayfasÃ„Â±", min_value=1, max_value=total_card_pages, value=1, key="card_page")
            card_start = (card_page - 1) * cards_per_page
            card_end = min(card_start + cards_per_page, len(df_display))
            cards_to_show = df_display.iloc[card_start:card_end]
            st.info(f"ÄŸÅ¸â€œâ€ GÃƒÂ¶sterilen kartlar: {card_start + 1}-{card_end} / {len(df_display)}")
        else:
            cards_to_show = df_display
        
        # Display cards - Simple and clean
        for idx, row in cards_to_show.iterrows():
            # Create ONE simple card per record
            with st.container():
                st.markdown(f"""
                <div style="
                    border: 1px solid #ddd;
                    border-radius: 8px;
                    padding: 15px;
                    margin: 10px 0;
                    background-color: #ffffff;
                ">
                    <h4 style="margin: 0 0 15px 0; color: #333;">KayÃ„Â±t #{idx + 1}</h4>
                """, unsafe_allow_html=True)
                
                # Show all fields simply
                for col_name, value in row.items():
                    if pd.isna(value):
                        display_value = "-"
                    else:
                        display_value = str(value)
                    
                    st.markdown(f"**{col_name}:** {display_value}")
                
                # Add favorite button with unique key
                col1, col2 = st.columns([1, 10])
                with col1:
                    # Use original index from dataframe for unique key
                    original_idx = df.index[idx]
                    record_id = f"record_{original_idx}"
                    is_favorite = record_id in st.session_state.favorites
                    
                    if st.button("Ã¢Â­Â" if not is_favorite else "ÄŸÅ¸â€™â€º", key=f"fav_card_{original_idx}", help="Favorilere ekle/ÃƒÂ§Ã„Â±kar"):
                        if is_favorite:
                            st.session_state.favorites.remove(record_id)
                            warning_msg = st.warning("ÄŸÅ¸â€™â€ Favorilerden ÃƒÂ§Ã„Â±karÃ„Â±ldÃ„Â±!")
                            time.sleep(1.5)
                            warning_msg.empty()
                        else:
                            st.session_state.favorites.append(record_id)
                            success_msg = st.success("Ã¢Â­Â Favorilere eklendi!")
                            time.sleep(1.5)
                            success_msg.empty()
                        st.rerun()
                
                st.markdown("</div>", unsafe_allow_html=True)
            
            # Add action buttons for each card
            card_action_cols = st.columns([1, 1, 1, 2])
            with card_action_cols[0]:
                if st.button(f"ÄŸÅ¸â€œâ€¹ Kopyala #{idx + 1}", key=f"copy_{idx}"):
                    card_text = f"KayÃ„Â±t #{idx + 1}:\n" + "\n".join([f"{col}: {val}" for col, val in row.items()])
                    st.info(f"ÄŸÅ¸â€œâ€¹ KayÃ„Â±t #{idx + 1} kopyalandÃ„Â±!")
            
            with card_action_cols[1]:
                if st.button(f"ÄŸÅ¸â€Â Detay #{idx + 1}", key=f"detail_{idx}"):
                    st.json(row.to_dict())
            
            with card_action_cols[2]:
                original_idx = df.index[idx]
                record_id = f"record_{original_idx}"
                is_favorite = record_id in st.session_state.favorites
                
                if st.button(f"Ã¢Â­Â Favori #{idx + 1}", key=f"fav_table_{original_idx}"):
                    if is_favorite:
                        # Favorilerden ÃƒÂ§Ã„Â±kar
                        st.session_state.favorites.remove(record_id)
                        warning_msg = st.warning(f"ÄŸÅ¸â€™â€ KayÃ„Â±t #{idx + 1} favorilerden ÃƒÂ§Ã„Â±karÃ„Â±ldÃ„Â±!")
                        time.sleep(1.5)
                        warning_msg.empty()
                    else:
                        # Favorilere ekle
                        st.session_state.favorites.append(record_id)
                        success_msg = st.success(f"Ã¢Â­Â KayÃ„Â±t #{idx + 1} favorilere eklendi!")
                        time.sleep(1.5)
                        success_msg.empty()
                    st.rerun()
            
            # Extra spacing between cards
            st.markdown("<br>", unsafe_allow_html=True)

    with tab2:
        st.subheader("ÄŸÅ¸â€œË† AkÃ„Â±llÃ„Â± Analitik ve Ã„Â°statistikler")
    
    # Smart statistics
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if numeric_cols:
        st.markdown("### ÄŸÅ¸â€œÅ  SayÃ„Â±sal Veriler Ã„Â°ÃƒÂ§in AkÃ„Â±llÃ„Â± Ã„Â°statistikler")
        
        # Auto-detect patterns and anomalies
        for col in numeric_cols[:3]:  # Limit to first 3 for performance
            with st.expander(f"ÄŸÅ¸â€œË† {col} - DetaylÃ„Â± Analiz"):
                col1, col2 = st.columns(2)
                
                with col1:
                    # Basic stats
                    stats = df[col].describe()
                    st.write("**Temel Ã„Â°statistikler:**")
                    for stat, value in stats.items():
                        st.write(f"Ã¢â‚¬Â¢ {stat.title()}: {value:.2f}")
                
                with col2:
                    # Smart insights
                    st.write("**AkÃ„Â±llÃ„Â± GÃƒÂ¶rÃƒÂ¼Ã…Å¸ler:**")
                    
                    # Detect outliers
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]
                    
                    if len(outliers) > 0:
                        st.warning(f"Ã¢Å¡Â Ã¯Â¸Â {len(outliers)} aykÃ„Â±rÃ„Â± deÃ„Å¸er tespit edildi")
                    else:
                        st.success("Ã¢Å“â€¦ AykÃ„Â±rÃ„Â± deÃ„Å¸er tespit edilmedi")
                    
                    # Distribution analysis
                    skewness = df[col].skew()
                    if abs(skewness) < 0.5:
                        st.info("ÄŸÅ¸â€œÅ  Normal daÃ„Å¸Ã„Â±lÃ„Â±ma yakÃ„Â±n")
                    elif skewness > 0.5:
                        st.warning("ÄŸÅ¸â€œË† SaÃ„Å¸a ÃƒÂ§arpÃ„Â±k daÃ„Å¸Ã„Â±lÃ„Â±m")
                    else:
                        st.warning("ÄŸÅ¸â€œâ€° Sola ÃƒÂ§arpÃ„Â±k daÃ„Å¸Ã„Â±lÃ„Â±m")
                
                # Smart visualization
                fig = smart_visualizer.create_smart_chart(df, col)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
    
    # Correlation analysis for multiple numeric columns
    if len(numeric_cols) >= 2:
        st.markdown("### ÄŸÅ¸â€â€” Korelasyon Analizi")
        correlation_matrix = df[numeric_cols].corr()
        
        # Create interactive heatmap
        fig_corr = px.imshow(
            correlation_matrix,
            text_auto=True,
            aspect="auto",
            color_continuous_scale="RdBu_r",
            title="DeÃ„Å¸iÃ…Å¸kenler ArasÃ„Â± Korelasyon"
        )
        st.plotly_chart(fig_corr, use_container_width=True)
        
        # Highlight strong correlations
        strong_correlations = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i+1, len(correlation_matrix.columns)):
                corr_val = correlation_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:
                    col1_name = correlation_matrix.columns[i]
                    col2_name = correlation_matrix.columns[j]
                    strong_correlations.append((col1_name, col2_name, corr_val))
        
        if strong_correlations:
            st.markdown("#### ÄŸÅ¸ÂÂ¯ GÃƒÂ¼ÃƒÂ§lÃƒÂ¼ Korelasyonlar")
            for col1, col2, corr in strong_correlations:
                correlation_type = "Pozitif" if corr > 0 else "Negatif"
                st.write(f"Ã¢â‚¬Â¢ **{col1}** Ã¢â€ â€ **{col2}**: {correlation_type} ({corr:.3f})")

    with tab3:
        st.subheader("ÄŸÅ¸â€Â GeliÃ…Å¸miÃ…Å¸ KeÃ…Å¸if ve Filtreler")
        df = normalize_columns(df_raw)
    
    # Smart search with suggestions
    st.markdown("### ÄŸÅ¸â€Â AkÃ„Â±llÃ„Â± Arama")
    search_col1, search_col2 = st.columns([3, 1])
    
    with search_col1:
        search_term = st.text_input("ÄŸÅ¸â€Â TÃƒÂ¼m verilerde ara...", placeholder="Aranacak kelime veya deÃ„Å¸er")
    with search_col2:
        case_sensitive = st.checkbox("BÃƒÂ¼yÃƒÂ¼k/kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k harf duyarlÃ„Â±")
    
    if search_term:
        # Smart search across all columns
        search_results = []
        for col in df.columns:
            if df[col].dtype == 'object':
                mask = df[col].astype(str).str.contains(search_term, case=case_sensitive, na=False)
            else:
                mask = df[col].astype(str).str.contains(str(search_term), case=case_sensitive, na=False)
            
            matches = df[mask]
            if len(matches) > 0:
                search_results.append((col, len(matches)))
        
        if search_results:
            st.success(f"ÄŸÅ¸ÂÂ¯ '{search_term}' iÃƒÂ§in {len(search_results)} sÃƒÂ¼tunda toplam {sum(count for _, count in search_results)} sonuÃƒÂ§ bulundu:")
            
            for col, count in search_results:
                st.write(f"Ã¢â‚¬Â¢ **{col}**: {count} eÃ…Å¸leÃ…Å¸me")
            
            # Show filtered results
            mask = df.astype(str).apply(lambda x: x.str.contains(search_term, case=case_sensitive, na=False)).any(axis=1)
            filtered_df = df[mask]
            st.dataframe(filtered_df, use_container_width=True)
        else:
            st.warning(f"Ã¢ÂÅ’ '{search_term}' iÃƒÂ§in sonuÃƒÂ§ bulunamadÃ„Â±")
    
    # Advanced filtering
    st.markdown("### Ã¢Å¡â„¢Ã¯Â¸Â GeliÃ…Å¸miÃ…Å¸ Filtreler")
    
    filter_col1, filter_col2 = st.columns(2)
    
    with filter_col1:
        # Numeric filters
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_columns:
            st.markdown("#### ÄŸÅ¸â€œÅ  SayÃ„Â±sal Filtreler")
            selected_numeric = st.selectbox("SayÃ„Â±sal sÃƒÂ¼tun seÃƒÂ§", ["SeÃƒÂ§iniz..."] + numeric_columns)
            
            if selected_numeric and selected_numeric != "SeÃƒÂ§iniz...":
                min_val = float(df[selected_numeric].min())
                max_val = float(df[selected_numeric].max())
                
                range_values = st.slider(
                    f"{selected_numeric} deÃ„Å¸er aralÃ„Â±Ã„Å¸Ã„Â±",
                    min_val, max_val, (min_val, max_val)
                )
                
                filtered_by_range = df[
                    (df[selected_numeric] >= range_values[0]) & 
                    (df[selected_numeric] <= range_values[1])
                ]
                
                st.info(f"ÄŸÅ¸â€œÅ  Filtrelenen satÃ„Â±r sayÃ„Â±sÃ„Â±: {len(filtered_by_range)}")
    
    with filter_col2:
        # Text filters
        text_columns = df.select_dtypes(include=['object']).columns.tolist()
        if text_columns:
            st.markdown("#### ÄŸÅ¸â€œÂ Metin Filtreleri")
            selected_text_col = st.selectbox("Metin sÃƒÂ¼tunu seÃƒÂ§", ["SeÃƒÂ§iniz..."] + text_columns)
            
            if selected_text_col and selected_text_col != "SeÃƒÂ§iniz...":
                unique_values = df[selected_text_col].dropna().unique()
                if len(unique_values) <= 50:  # Show multiselect for reasonable number of options
                    selected_values = st.multiselect(
                        f"{selected_text_col} deÃ„Å¸erleri",
                        unique_values
                    )
                    
                    if selected_values:
                        filtered_by_text = df[df[selected_text_col].isin(selected_values)]
                        st.info(f"ÄŸÅ¸â€œÂ Filtrelenen satÃ„Â±r sayÃ„Â±sÃ„Â±: {len(filtered_by_text)}")
                else:
                    st.info(f"Ã¢Å¡Â Ã¯Â¸Â Ãƒâ€¡ok fazla benzersiz deÃ„Å¸er ({len(unique_values)}). Arama kutusunu kullanÃ„Â±n.")

    with tab4:
        st.subheader("Ã¢Â­Â Favori KayÃ„Â±tlarÃ„Â±m")
        
        if not st.session_state.favorites:
            st.info("ÄŸÅ¸â€™â€ HenÃƒÂ¼z favori kaydÃ„Â±nÃ„Â±z yok.")
            st.markdown("""
            **Favori nasÃ„Â±l eklenir?**
            1. ÄŸÅ¸â€œÅ  Veri Analizi sekmesine gidin
            2. Kart gÃƒÂ¶rÃƒÂ¼nÃƒÂ¼mÃƒÂ¼nÃƒÂ¼ seÃƒÂ§in
            3. BeÃ„Å¸endiÃ„Å¸iniz kayÃ„Â±tta Ã¢Â­Â butonuna tÃ„Â±klayÃ„Â±n
            """)
        else:
            # Favori istatistikleri
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Toplam Favori", len(st.session_state.favorites))
            with col2:
                if st.button("ÄŸÅ¸â€”â€˜Ã¯Â¸Â TÃƒÂ¼mÃƒÂ¼nÃƒÂ¼ Temizle"):
                    st.session_state.favorites = []
                success_msg = st.success("ÄŸÅ¸â€”â€˜Ã¯Â¸Â TÃƒÂ¼m favoriler temizlendi!")
                time.sleep(2)
                success_msg.empty()
                st.rerun()
        
        st.markdown("---")
        
        # Favori kayÃ„Â±tlarÃ„Â± gÃƒÂ¶ster
        for i, record_id in enumerate(st.session_state.favorites):
            # Record ID'den index'i ÃƒÂ§Ã„Â±kar
            index = int(record_id.split('_')[1])
            
            # Orijinal veriden kayÃ„Â±t bul
            if index in df.index:
                row = df.loc[index]
                
                # Basit favori kartÃ„Â±
                st.markdown(f"""
                <div style="
                    border: 2px solid #f39c12;
                    border-radius: 8px;
                    padding: 15px;
                    margin: 10px 0;
                    background-color: #fff8e1;
                ">
                    <h4 style="margin: 0 0 15px 0; color: #e67e22;">Ã¢Â­Â Favori KayÃ„Â±t #{i + 1}</h4>
                """, unsafe_allow_html=True)
                
                # TÃƒÂ¼m alanlarÃ„Â± gÃƒÂ¶ster
                for col_name, value in row.items():
                    if pd.isna(value):
                        display_value = "-"
                    else:
                        display_value = str(value)
                    
                    st.markdown(f"**{col_name}:** {display_value}")
                
                # Favoriden ÃƒÂ§Ã„Â±kar butonu
                if st.button(f"ÄŸÅ¸â€™â€ Favoriden Ãƒâ€¡Ã„Â±kar", key=f"remove_fav_{index}"):
                    st.session_state.favorites.remove(record_id)
                    success_msg = st.success("ÄŸÅ¸â€™â€ Favorilerden ÃƒÂ§Ã„Â±karÃ„Â±ldÃ„Â±!")
                    time.sleep(1.5)
                    success_msg.empty()
                    st.rerun()
                
                st.markdown("</div>", unsafe_allow_html=True)
            else:
                st.warning(f"KayÃ„Â±t #{index} artÃ„Â±k mevcut deÃ„Å¸il.")

    with tab5:
        st.subheader("Ã¢Å¡Â¡ Performans Ã„Â°zleme ve Optimizasyon")
        
        # Performance metrics
    perf_stats = st.session_state.perf_monitor.get_stats()
    
    if perf_stats:
        st.markdown("### ÄŸÅ¸â€œÅ  Performans Metrikleri")
        
        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Toplam Ã„Â°Ã…Å¸lem", 
                perf_stats['total_operations'],
                delta=f"{perf_stats['successful_operations']} baÃ…Å¸arÃ„Â±lÃ„Â±"
            )
        
        with col2:
            avg_time = perf_stats['average_execution_time']
            st.metric("Ortalama SÃƒÂ¼re", f"{avg_time:.2f}s")
        
        with col3:
            cache_stats = st.session_state.smart_cache.get_stats()
            hit_rate = (cache_stats['hits'] / max(cache_stats['total_requests'], 1)) * 100
            st.metric("Cache Hit Rate", f"{hit_rate:.1f}%")
        
        with col4:
            current_memory = df_raw.memory_usage(deep=True).sum() / 1024**2
            st.metric("Bellek KullanÃ„Â±mÃ„Â±", f"{current_memory:.1f} MB")
        
        # Detailed operation history
        if st.checkbox("ÄŸÅ¸â€Â DetaylÃ„Â± Ã„Â°Ã…Å¸lem GeÃƒÂ§miÃ…Å¸i"):
            history = st.session_state.perf_monitor.operation_history
            if history:
                history_df = pd.DataFrame([
                    {
                        'Ã„Â°Ã…Å¸lem': op['operation'],
                        'BaÃ…Å¸langÃ„Â±ÃƒÂ§': op['start_time'].strftime('%H:%M:%S'),
                        'SÃƒÂ¼re (s)': f"{op.get('duration', 0):.3f}",
                        'Durum': 'Ã¢Å“â€¦ BaÃ…Å¸arÃ„Â±lÃ„Â±' if op.get('success', False) else 'Ã¢ÂÅ’ HatalÃ„Â±'
                    } for op in history[-20:]  # Son 20 iÃ…Å¸lem
                ])
                st.dataframe(history_df, use_container_width=True)
        
        # Performance recommendations
        st.markdown("### ÄŸÅ¸â€™Â¡ Performans Ãƒâ€“nerileri")
        
        recommendations = []
        
        if len(df_raw) > 10000:
            recommendations.append("ÄŸÅ¸â€œÅ  BÃƒÂ¼yÃƒÂ¼k veri seti tespit edildi. Filtreleme kullanarak performansÃ„Â± artÃ„Â±rabilirsiniz.")
        
        if perf_stats['average_execution_time'] > 2.0:
            recommendations.append("Ã¢ÂÂ±Ã¯Â¸Â Ortalama iÃ…Å¸lem sÃƒÂ¼resi yÃƒÂ¼ksek. Cache kullanÃ„Â±mÃ„Â±nÃ„Â± artÃ„Â±rÃ„Â±n.")
        
        cache_stats = st.session_state.smart_cache.get_stats()
        hit_rate = (cache_stats['hits'] / max(cache_stats['total_requests'], 1)) * 100
        if hit_rate < 50:
            recommendations.append("ÄŸÅ¸â€™Â¾ Cache hit rate dÃƒÂ¼Ã…Å¸ÃƒÂ¼k. Benzer sorgularÃ„Â± tekrar kullanmaya ÃƒÂ§alÃ„Â±Ã…Å¸Ã„Â±n.")
        
        current_memory = df_raw.memory_usage(deep=True).sum() / 1024**2
        if current_memory > 100:
            recommendations.append("ÄŸÅ¸Â§Â  YÃƒÂ¼ksek bellek kullanÃ„Â±mÃ„Â±. Daha kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k veri setleri ile ÃƒÂ§alÃ„Â±Ã…Å¸mayÃ„Â± deneyin.")
        
        if not recommendations:
            recommendations.append("Ã¢Å“â€¦ Performans optimal gÃƒÂ¶rÃƒÂ¼nÃƒÂ¼yor!")
        
        for rec in recommendations:
            st.info(rec)
    
    else:
        st.info("ÄŸÅ¸â€œÅ  HenÃƒÂ¼z performans verisi yok. BirkaÃƒÂ§ iÃ…Å¸lem yapÃ„Â±n ve geri dÃƒÂ¶nÃƒÂ¼n.")
    
    # System info
    with st.expander("ÄŸÅ¸â€“Â¥Ã¯Â¸Â Sistem Bilgileri"):
        st.json({
            "Python Version": sys.version,
            "Pandas Version": pd.__version__,
            "Streamlit Version": st.__version__,
            "Platform": sys.platform
        })

# -------------------------
# Kenar Ãƒâ€¡ubuÃ„Å¸u Ã¢â‚¬â€ Filtreler
# -------------------------
st.sidebar.header("ÄŸÅ¸â€Â Filtreler ve Arama")

# ÄŸÅ¸ÂÂ¤ Voice Search
st.sidebar.subheader("ÄŸÅ¸ÂÂ¤ Sesli Sor")

# Sesli arama yardÃ„Â±m mesajÃ„Â±
with st.sidebar.expander("ÄŸÅ¸Â¤â€“ AI Sesli Asistan NasÃ„Â±l KullanÃ„Â±lÃ„Â±r?", expanded=False):
    st.write("""
    **ÄŸÅ¸Â¤â€“ AI Sesli Asistan KomutlarÃ„Â±:**
    
    ÄŸÅ¸â€œÅ  **Ã„Â°ÃƒÂ§erik Filtreleme:**
    Ã¢â‚¬Â¢ "Tabloda adÃ„Â± Ahmet olanlarÃ„Â± getir"
    Ã¢â‚¬Â¢ "Ã„Â°smi Mehmet olan kayÃ„Â±tlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Talep aÃƒÂ§Ã„Â±klamasÃ„Â± iÃƒÂ§erisinde merhaba yazan verileri getir"
    Ã¢â‚¬Â¢ "YanÃ„Â±t sÃƒÂ¼tununda teÃ…Å¸ekkÃƒÂ¼r geÃƒÂ§en kayÃ„Â±tlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Problem kelimesi bulunan satÃ„Â±rlarÃ„Â± gÃƒÂ¶ster"
    
    ÄŸÅ¸â€œË† **AkÃ„Â±llÃ„Â± Sayma:**
    Ã¢â‚¬Â¢ "AdÃ„Â± Ahmet olan kaÃƒÂ§ kiÃ…Å¸i var?"
    Ã¢â‚¬Â¢ "KaÃƒÂ§ tane merhaba kelimesi var?"
    Ã¢â‚¬Â¢ "Talep aÃƒÂ§Ã„Â±klamasÃ„Â±nda problem yazan kaÃƒÂ§ kayÃ„Â±t var?"
    Ã¢â‚¬Â¢ "Toplam kaÃƒÂ§ adet ankara yazÃ„Â±yor?"
    
    ÄŸÅ¸â€œâ€¹ **Dinamik SÃƒÂ¼tun SeÃƒÂ§imi:**
    Ã¢â‚¬Â¢ "Sadece talep aÃƒÂ§Ã„Â±klamasÃ„Â± sÃƒÂ¼tununu gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "YanÃ„Â±t sÃƒÂ¼tununu getir"
    Ã¢â‚¬Â¢ "AÃƒÂ§Ã„Â±klama sÃƒÂ¼tunlarÃ„Â±nÃ„Â± getir"
    Ã¢â‚¬Â¢ "Ã„Â°lk 3 sÃƒÂ¼tunu gÃƒÂ¶ster"
    
    ÄŸÅ¸â€œâ€ **KayÃ„Â±t SÃ„Â±nÃ„Â±rlama:**
    Ã¢â‚¬Â¢ "Ã„Â°lk 10 kaydÃ„Â± getir"
    Ã¢â‚¬Â¢ "Son 5 kayÃ„Â±t gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Ã„Â°lk 20 satÃ„Â±rÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Son 15 kaydÃ„Â± getir"
    
    ÄŸÅ¸â€Â **KapsamlÃ„Â± Arama:**
    Ã¢â‚¬Â¢ "123 numaralÃ„Â± kayÃ„Â±tlarÃ„Â± bul"
    Ã¢â‚¬Â¢ "Ankara yazanlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Admin kelimesini ara"
    Ã¢â‚¬Â¢ "Email adresi olanlarÃ„Â± getir"
    
    ÄŸÅ¸â€œâ€¦ **Tarih ve SayÃ„Â± Filtreleri:**
    Ã¢â‚¬Â¢ "2024 yÃ„Â±lÃ„Â±ndaki kayÃ„Â±tlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "100'den bÃƒÂ¼yÃƒÂ¼k deÃ„Å¸erleri bul"
    Ã¢â‚¬Â¢ "BugÃƒÂ¼nkÃƒÂ¼ tarihi iÃƒÂ§erenler"
    
    ÄŸÅ¸ÂÂ¯ **GeliÃ…Å¸miÃ…Å¸ Komutlar:**
    Ã¢â‚¬Â¢ "BoÃ…Å¸ hÃƒÂ¼creleri gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Tekrar eden kayÃ„Â±tlarÃ„Â± bul"
    Ã¢â‚¬Â¢ "En uzun aÃƒÂ§Ã„Â±klamayÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "KÃ„Â±sa yanÃ„Â±tlarÃ„Â± filtrele"
    Ã¢â‚¬Â¢ "BÃƒÂ¼yÃƒÂ¼k harfle yazÃ„Â±lanlarÃ„Â± bul"
    
    ÄŸÅ¸â€Â¢ **Ã„Â°statistik KomutlarÃ„Â±:**
    Ã¢â‚¬Â¢ "Ortalama deÃ„Å¸eri nedir?"
    Ã¢â‚¬Â¢ "En yÃƒÂ¼ksek deÃ„Å¸er hangisi?"
    Ã¢â‚¬Â¢ "Toplam kayÃ„Â±t sayÃ„Â±sÃ„Â± kaÃƒÂ§?"
    Ã¢â‚¬Â¢ "Benzersiz deÃ„Å¸er sayÃ„Â±sÃ„Â±?"
    
    **ÄŸÅ¸ÂÂ¯ AI Ãƒâ€“zellikler:**
    Ã¢â‚¬Â¢ SÃƒÂ¼tun isimlerini otomatik tanÃ„Â±r
    Ã¢â‚¬Â¢ BÃƒÂ¼yÃƒÂ¼k/kÃƒÂ¼ÃƒÂ§ÃƒÂ¼k harf duyarlÃ„Â± deÃ„Å¸il
    Ã¢â‚¬Â¢ TÃƒÂ¼rkÃƒÂ§e doÃ„Å¸al dil iÃ…Å¸leme
    Ã¢â‚¬Â¢ AkÃ„Â±llÃ„Â± kelime eÃ…Å¸leÃ…Å¸tirme
    Ã¢â‚¬Â¢ SayÃ„Â±sal karÃ…Å¸Ã„Â±laÃ…Å¸tÃ„Â±rmalar
    Ã¢â‚¬Â¢ Tarih formatlarÃ„Â±nÃ„Â± anlÃ„Â±yor
    Ã¢â‚¬Â¢ "KaÃƒÂ§ tane" diyerek sayÃ„Â±m yapabilirsiniz
    """)

    # Mevcut sÃƒÂ¼tunlarÃ„Â± gÃƒÂ¶ster
    if 'df' in locals():
        st.write("**ÄŸÅ¸â€œâ€¹ Mevcut SÃƒÂ¼tunlar:**")
        for col in df.columns:
            st.write(f"Ã¢â‚¬Â¢ {col}")
    

col_voice1, col_voice2 = st.sidebar.columns([3, 1])

with col_voice1:
    if st.button("ÄŸÅ¸ÂÂ¤ Sesli Sor", key="voice_search", help="Mikrofona tÃ„Â±klayÃ„Â±p sorunuzu sorun"):
        voice_result = get_voice_input()
        st.session_state["voice_query"] = voice_result

with col_voice2:
    if st.button("ÄŸÅ¸â€â€", key="voice_clear", help="Sesli soruyu temizle"):
        st.session_state["voice_query"] = ""

# Sesli arama sonucu gÃƒÂ¶ster
if "voice_query" in st.session_state and st.session_state["voice_query"]:
    st.sidebar.info(f"ÄŸÅ¸ÂÂ¤ Sesli Komut: {st.session_state['voice_query']}")
    
    # SonuÃƒÂ§ mesajÃ„Â±nÃ„Â± gÃƒÂ¶ster
    if "voice_result_message" in st.session_state and st.session_state["voice_result_message"]:
        if "bulundu" in st.session_state["voice_result_message"] or "gÃƒÂ¶steriliyor" in st.session_state["voice_result_message"]:
            st.sidebar.success(f"Ã¢Å“â€¦ {st.session_state['voice_result_message']}")
        else:
            st.sidebar.warning(f"Ã¢Å¡Â Ã¯Â¸Â {st.session_state['voice_result_message']}")
    
    if st.session_state["voice_query"] not in ["Zaman aÃ…Å¸Ã„Â±mÃ„Â± - tekrar deneyin", "Ses anlaÃ…Å¸Ã„Â±lamadÃ„Â±", "Ses tanÃ„Â±ma servisi hatasÃ„Â±"]:
        # Sesli aramayÃ„Â± uygula
        df = process_voice_search(st.session_state["voice_query"], df)

st.sidebar.markdown("---")

# ÄŸÅ¸â€™Â¬ AI Chat Ãƒâ€“zelliÃ„Å¸i
st.sidebar.subheader("ÄŸÅ¸â€™Â¬ AI Chat Asistan")

# Chat yardÃ„Â±m mesajÃ„Â±
with st.sidebar.expander("ÄŸÅ¸â€™Â¡ Chat Asistan NasÃ„Â±l KullanÃ„Â±lÃ„Â±r?", expanded=False):
    st.write("""
    **ÄŸÅ¸â€™Â¬ AI Chat KomutlarÃ„Â±:**
    
    ÄŸÅ¸â€Â **DoÃ„Å¸al Dil ile Arama:**
    Ã¢â‚¬Â¢ "Tabloda adÃ„Â± Tolga olanlarÃ„Â± getir"
    Ã¢â‚¬Â¢ "Ã…Âehri Ã„Â°stanbul olan kayÃ„Â±tlarÃ„Â± bul"
    Ã¢â‚¬Â¢ "Telefonu 532 ile baÃ…Å¸layanlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Email adresi gmail olanlarÃ„Â± filtrele"
    
    ÄŸÅ¸â€œÅ  **AkÃ„Â±llÃ„Â± Sorgular:**
    Ã¢â‚¬Â¢ "KaÃƒÂ§ farklÃ„Â± Ã…Å¸ehir var?"
    Ã¢â‚¬Â¢ "En uzun aÃƒÂ§Ã„Â±klama hangisi?"
    Ã¢â‚¬Â¢ "BoÃ…Å¸ telefon alanlarÃ„Â± gÃƒÂ¶ster"
    Ã¢â‚¬Â¢ "Ã„Â°lk 5 kaydÃ„Â± getir"
    
    ÄŸÅ¸â€™Â¡ **Ã„Â°puÃƒÂ§larÃ„Â±:**
    Ã¢â‚¬Â¢ DoÃ„Å¸al TÃƒÂ¼rkÃƒÂ§e ile yazÃ„Â±n
    Ã¢â‚¬Â¢ SÃƒÂ¼tun isimlerini tam bilmeniz gerekmez
    Ã¢â‚¬Â¢ "getir", "gÃƒÂ¶ster", "bul" gibi kelimeler kullanÃ„Â±n
    """)

# Chat input
col_chat1, col_chat2 = st.sidebar.columns([5, 1])

# Chat temizleme kontrolÃƒÂ¼
if 'clear_chat' not in st.session_state:
    st.session_state['clear_chat'] = False

with col_chat1:
    # Chat temizlenecekse boÃ…Å¸ deÃ„Å¸er kullan
    default_value = "" if st.session_state.get('clear_chat', False) else st.session_state.get("chat_input", "")
    
    # Form kullanarak Enter tuÃ…Å¸u ile submit yapalÃ„Â±m
    with st.form(key="chat_form", clear_on_submit=True):
        chat_query = st.text_area(
            "ÄŸÅ¸â€™Â¬ Sorunuzu yazÃ„Â±n:",
            value=default_value,
            placeholder="Ãƒâ€“rn: AdÃ„Â± Ahmet olanlarÃ„Â± getir (Enter ile ara)",
            height=80,
            key="chat_textarea"
        )
        
        # Submit butonu (gÃƒÂ¶rÃƒÂ¼nmez)
        submit_button = st.form_submit_button("ÄŸÅ¸â€Â Ara", use_container_width=True)
    
    # Form submit edilince chat_query'yi iÃ…Å¸le
    if submit_button and chat_query and chat_query.strip():
        st.session_state['submitted_chat_query'] = chat_query.strip()

with col_chat2:
    st.write("")  # BoÃ…Å¸ satÃ„Â±r ekle
    if st.button("ÄŸÅ¸â€”â€˜Ã¯Â¸Â", key="chat_clear", help="Chat'i temizle"):
        st.session_state['clear_chat'] = True
        if 'chat_result_message' in st.session_state:
            del st.session_state['chat_result_message']
        if 'chat_history' in st.session_state:
            st.session_state['chat_history'] = []
        if 'submitted_chat_query' in st.session_state:
            del st.session_state['submitted_chat_query']
        st.rerun()

# Clear flag'i sÃ„Â±fÃ„Â±rla
if st.session_state.get('clear_chat', False):
    st.session_state['clear_chat'] = False

# Chat sonucu iÃ…Å¸le
# Form'dan gelen sorgu varsa iÃ…Å¸le
if 'submitted_chat_query' in st.session_state:
    chat_query = st.session_state['submitted_chat_query']
    del st.session_state['submitted_chat_query']  # Bir kez kullan
else:
    chat_query = None

if chat_query and chat_query.strip():
    st.sidebar.info(f"ÄŸÅ¸â€™Â¬ Chat Komutu: {chat_query}")
    
    # Ana sayfada progress bar gÃƒÂ¶ster
    progress_placeholder = st.empty()
    
    with progress_placeholder.container():
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.info("ÄŸÅ¸â€Â AI Arama yapÃ„Â±lÃ„Â±yor...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Progress bar animasyonu
            for i in range(100):
                progress_bar.progress(i + 1)
                if i < 30:
                    status_text.text("ÄŸÅ¸â€Â SÃƒÂ¼tunlar analiz ediliyor...")
                elif i < 60:
                    status_text.text("ÄŸÅ¸Â§Â  AI komutu iÃ…Å¸leniyor...")
                elif i < 90:
                    status_text.text("ÄŸÅ¸â€œÅ  Veriler filtreleniyor...")
                else:
                    status_text.text("Ã¢Å“â€¦ SonuÃƒÂ§lar hazÃ„Â±rlanÃ„Â±yor...")
                time.sleep(0.02)  # Biraz daha hÃ„Â±zlÃ„Â±
    
    # Chat komutunu sesli asistan ile aynÃ„Â± mantÃ„Â±kla iÃ…Å¸le
    chat_filtered_df, chat_message = smart_voice_assistant(chat_query, df)
    
    # Progress bar'Ã„Â± temizle
    progress_placeholder.empty()
    
    # Ana sayfada sonuÃƒÂ§ mesajÃ„Â±nÃ„Â± gÃƒÂ¶ster
    if "bulundu" in chat_message or "gÃƒÂ¶steriliyor" in chat_message or "seÃƒÂ§ildi" in chat_message:
        st.success(f"Ã¢Å“â€¦ {chat_message}")
        # Chat sonucunu ana dataframe'e uygula
        df = chat_filtered_df
    else:
        st.warning(f"Ã¢Å¡Â Ã¯Â¸Â {chat_message}")
    
    # Sidebar'da da gÃƒÂ¶ster
    st.sidebar.success(f"Ã¢Å“â€¦ Arama tamamlandÃ„Â±!")
    
    # Chat geÃƒÂ§miÃ…Å¸ini session state'e kaydet
    if 'chat_history' not in st.session_state:
        st.session_state['chat_history'] = []
    
    # Yeni komutu geÃƒÂ§miÃ…Å¸e ekle
    st.session_state['chat_history'].append({
        'query': chat_query,
        'result': chat_message,
        'timestamp': pd.Timestamp.now().strftime("%H:%M")
    })
    
    # Son 5 komutu tut
    if len(st.session_state['chat_history']) > 5:
        st.session_state['chat_history'] = st.session_state['chat_history'][-5:]
    
    # Session state'e kaydet
    st.session_state['chat_result_message'] = chat_message

# Chat geÃƒÂ§miÃ…Å¸ini gÃƒÂ¶ster
if 'chat_history' in st.session_state and st.session_state['chat_history']:
    with st.sidebar.expander("ÄŸÅ¸â€œÅ“ Son Chat GeÃƒÂ§miÃ…Å¸i", expanded=False):
        for i, chat in enumerate(reversed(st.session_state['chat_history'])):
            st.write(f"**{chat['timestamp']}** - {chat['query']}")
            if "bulundu" in chat['result']:
                st.success(f"Ã¢Å“â€¦ {chat['result']}")
            else:
                st.info(f"Ã¢â€Â¹Ã¯Â¸Â {chat['result']}")
            st.write("---")

else:
    st.info(" BaÅŸlamak iÃ§in **.xlsx** dosyanÄ±zÄ± yÃ¼kleyin veya soldan bir dosya seÃ§in.")
